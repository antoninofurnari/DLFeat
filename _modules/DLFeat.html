

<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="../">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>DLFeat &mdash; DLFeat 0.3.1 documentation</title>
      <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=b86133f3" />
      <link rel="stylesheet" type="text/css" href="../_static/css/theme.css?v=e59714d7" />

  
      <script src="../_static/jquery.js?v=5d32c60e"></script>
      <script src="../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
      <script src="../_static/documentation_options.js?v=4621528c"></script>
      <script src="../_static/doctools.js?v=9bcbadda"></script>
      <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../index.html" class="icon icon-home">
            DLFeat
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <!-- Local TOC -->
              <div class="local-toc"></div>
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">DLFeat</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="index.html">Module code</a></li>
      <li class="breadcrumb-item active">DLFeat</li>
      <li class="wy-breadcrumbs-aside">
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <h1>Source code for DLFeat</h1><div class="highlight"><pre>
<span></span><span class="c1"># DLFeat: Deep Learning Feature Extraction Library</span>
<span class="c1"># Inspired by VLFeat for ease of use and modularity in the modern deep learning era.</span>
<span class="c1"># Version: 0.3.1</span>
<span class="c1"># Author: Gemini</span>
<span class="c1"># Date: 2025-05-31</span>

<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DLFeat: Deep Learning Feature Extraction Library</span>
<span class="sd">================================================</span>
<span class="sd"># ... (Main docstring same as v0.3.0, will update Model Zoo entry for Video Swin)</span>
<span class="sd">This version switches Video Swin Transformer to use the torchvision implementation.</span>
<span class="sd"># ...</span>

<span class="sd">Model Zoo</span>
<span class="sd">---------</span>
<span class="sd"># ... (Model Zoo table to be updated for Video Swin source)</span>
<span class="sd">.. list-table:: DLFeat Model Zoo (Excerpt for Video Swin Change)</span>
<span class="sd">   :widths: 15 25 10 10 10 10 15 15</span>
<span class="sd">   :header-rows: 1</span>

<span class="sd">   * - Modality</span>
<span class="sd">     - Model Name (Identifier)</span>
<span class="sd">     - Feat. Dim</span>
<span class="sd">     - Performance (Benchmark)</span>
<span class="sd">     - FLOPS (G)</span>
<span class="sd">     - Speed (Ref.)</span>
<span class="sd">     - Supervision</span>
<span class="sd">     - Source</span>
<span class="sd">   * - Video</span>
<span class="sd">     - `video_swin_t`</span>
<span class="sd">     - 768</span>
<span class="sd">     - ~78.8% (K400 Top-1, Swin-T)</span>
<span class="sd">     - 48 (32x224^2)</span>
<span class="sd">     - Medium</span>
<span class="sd">     - Supervised</span>
<span class="sd">     - torchvision</span>
<span class="sd">   * - Video</span>
<span class="sd">     - `video_swin_b`</span>
<span class="sd">     - 1024</span>
<span class="sd">     - ~80.6% (K400 Top-1, Swin-B)</span>
<span class="sd">     - 92 (32x224^2)</span>
<span class="sd">     - Slower</span>
<span class="sd">     - Supervised</span>
<span class="sd">     - torchvision</span>


<span class="sd">*(Note: Full Model Zoo table is extensive and located at the beginning of the file.</span>
<span class="sd">Performance, FLOPS, and Speed are indicative.)*</span>

<span class="sd">&quot;&quot;&quot;</span>

<span class="n">__version__</span> <span class="o">=</span> <span class="s2">&quot;0.3.1&quot;</span> 

<span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torchvision.transforms</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">T</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torchvision.models</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">tv_models</span> 
<span class="kn">import</span><span class="w"> </span><span class="nn">torchvision.models.video</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">tv_video_models</span> 
<span class="kn">from</span><span class="w"> </span><span class="nn">PIL</span><span class="w"> </span><span class="kn">import</span> <span class="n">Image</span><span class="p">,</span> <span class="n">ImageDraw</span> 
<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">warnings</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">os</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">textwrap</span> 

<span class="k">try</span><span class="p">:</span>
    <span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.base</span><span class="w"> </span><span class="kn">import</span> <span class="n">BaseEstimator</span><span class="p">,</span> <span class="n">TransformerMixin</span>
<span class="k">except</span> <span class="ne">ImportError</span><span class="p">:</span>
    <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span>
        <span class="s2">&quot;scikit-learn not found. DLFeatExtractor will not be scikit-learn compatible. &quot;</span>
        <span class="s2">&quot;Please install it: pip install scikit-learn&quot;</span>
    <span class="p">)</span>
    <span class="k">class</span><span class="w"> </span><span class="nc">BaseEstimator</span><span class="p">:</span> <span class="k">pass</span>
    <span class="k">class</span><span class="w"> </span><span class="nc">TransformerMixin</span><span class="p">:</span> <span class="k">pass</span>

<span class="k">try</span><span class="p">:</span>
    <span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="p">(</span>
        <span class="n">AutoProcessor</span><span class="p">,</span> <span class="n">AutoModel</span><span class="p">,</span> <span class="n">AutoTokenizer</span><span class="p">,</span> <span class="n">Wav2Vec2FeatureExtractor</span><span class="p">,</span>
        <span class="n">AutoImageProcessor</span><span class="p">,</span> 
        <span class="n">CLIPProcessor</span><span class="p">,</span> <span class="n">CLIPModel</span><span class="p">,</span> <span class="n">BlipProcessor</span><span class="p">,</span> <span class="n">BlipModel</span><span class="p">,</span>
        <span class="n">VideoMAEFeatureExtractor</span><span class="p">,</span> <span class="n">VideoMAEModel</span><span class="p">,</span> <span class="c1"># VideoMAE still from Transformers</span>
        <span class="n">XCLIPProcessor</span><span class="p">,</span> <span class="n">XCLIPModel</span><span class="p">,</span>
        <span class="n">ASTFeatureExtractor</span><span class="p">,</span>
        <span class="n">Dinov2Model</span> 
        <span class="c1"># VideoSwinModel, VideoSwinImageProcessor removed as VideoSwin is now from torchvision</span>
    <span class="p">)</span>
<span class="k">except</span> <span class="ne">ImportError</span><span class="p">:</span>
    <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span>
        <span class="s2">&quot;Transformers library not found or key components are missing. &quot;</span>
        <span class="s2">&quot;Text, some audio, DINOv2, VideoMAE and multimodal models may not be available. &quot;</span>
        <span class="s2">&quot;Please install or upgrade transformers: pip install --upgrade transformers&quot;</span>
    <span class="p">)</span>
    <span class="k">class</span><span class="w"> </span><span class="nc">AutoProcessor</span><span class="p">:</span> <span class="k">pass</span><span class="p">;</span> 
    <span class="k">class</span><span class="w"> </span><span class="nc">AutoModel</span><span class="p">:</span> <span class="k">pass</span><span class="p">;</span> 
    <span class="k">class</span><span class="w"> </span><span class="nc">AutoTokenizer</span><span class="p">:</span> <span class="k">pass</span><span class="p">;</span>
    <span class="k">class</span><span class="w"> </span><span class="nc">Wav2Vec2FeatureExtractor</span><span class="p">:</span> <span class="k">pass</span><span class="p">;</span> 
    <span class="k">class</span><span class="w"> </span><span class="nc">AutoImageProcessor</span><span class="p">:</span> <span class="k">pass</span><span class="p">;</span>
    <span class="k">class</span><span class="w"> </span><span class="nc">CLIPProcessor</span><span class="p">:</span> <span class="k">pass</span><span class="p">;</span> 
    <span class="k">class</span><span class="w"> </span><span class="nc">CLIPModel</span><span class="p">:</span> <span class="k">pass</span><span class="p">;</span> 
    <span class="k">class</span><span class="w"> </span><span class="nc">BlipProcessor</span><span class="p">:</span> <span class="k">pass</span><span class="p">;</span>
    <span class="k">class</span><span class="w"> </span><span class="nc">BlipModel</span><span class="p">:</span> <span class="k">pass</span><span class="p">;</span> 
    <span class="k">class</span><span class="w"> </span><span class="nc">VideoMAEFeatureExtractor</span><span class="p">:</span> <span class="k">pass</span><span class="p">;</span> 
    <span class="k">class</span><span class="w"> </span><span class="nc">VideoMAEModel</span><span class="p">:</span> <span class="k">pass</span><span class="p">;</span>
    <span class="k">class</span><span class="w"> </span><span class="nc">XCLIPProcessor</span><span class="p">:</span> <span class="k">pass</span><span class="p">;</span> 
    <span class="k">class</span><span class="w"> </span><span class="nc">XCLIPModel</span><span class="p">:</span> <span class="k">pass</span><span class="p">;</span> 
    <span class="k">class</span><span class="w"> </span><span class="nc">ASTFeatureExtractor</span><span class="p">:</span> <span class="k">pass</span><span class="p">;</span>
    <span class="k">class</span><span class="w"> </span><span class="nc">Dinov2Model</span><span class="p">:</span> <span class="k">pass</span><span class="p">;</span> <span class="c1"># VideoSwinModel, VideoSwinImageProcessor dummies removed</span>


<span class="k">try</span><span class="p">:</span>
    <span class="kn">from</span><span class="w"> </span><span class="nn">sentence_transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">SentenceTransformer</span>
<span class="k">except</span> <span class="ne">ImportError</span><span class="p">:</span>
    <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span>
        <span class="s2">&quot;Sentence-Transformers library not found. `sentence-bert` model will not be available. &quot;</span>
        <span class="s2">&quot;Please install it: pip install sentence-transformers&quot;</span>
    <span class="p">)</span>
    <span class="k">class</span><span class="w"> </span><span class="nc">SentenceTransformer</span><span class="p">:</span> <span class="k">pass</span>

<span class="k">try</span><span class="p">:</span>
    <span class="kn">import</span><span class="w"> </span><span class="nn">timm</span>
<span class="k">except</span> <span class="ne">ImportError</span><span class="p">:</span>
    <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span>
        <span class="s2">&quot;TIMM library not found. Some image models (ViT, EfficientNet, ConvNeXt, TSM) will not be available. &quot;</span>
        <span class="s2">&quot;Please install it: pip install timm&quot;</span>
    <span class="p">)</span>
    <span class="k">class</span><span class="w"> </span><span class="nc">timm</span><span class="p">:</span>
        <span class="nd">@staticmethod</span>
        <span class="k">def</span><span class="w"> </span><span class="nf">create_model</span><span class="p">(</span><span class="n">model_name</span><span class="p">,</span> <span class="n">pretrained</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">num_classes</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">ImportError</span><span class="p">(</span><span class="s2">&quot;TIMM library is not installed.&quot;</span><span class="p">)</span>

<span class="k">try</span><span class="p">:</span>
    <span class="kn">import</span><span class="w"> </span><span class="nn">torchaudio</span>
    <span class="kn">import</span><span class="w"> </span><span class="nn">torchaudio.transforms</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">TA</span>
    <span class="kn">import</span><span class="w"> </span><span class="nn">scipy.io.wavfile</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">scipy_wav</span>
<span class="k">except</span> <span class="ne">ImportError</span><span class="p">:</span>
    <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span>
        <span class="s2">&quot;Torchaudio or Scipy library not found. Audio processing or self-tests for audio might be limited. &quot;</span>
        <span class="s2">&quot;Please install them: pip install torchaudio scipy&quot;</span>
    <span class="p">)</span>
    <span class="k">class</span><span class="w"> </span><span class="nc">torchaudio</span><span class="p">:</span> <span class="k">pass</span> 
    <span class="k">class</span><span class="w"> </span><span class="nc">TA</span><span class="p">:</span> <span class="k">pass</span> 
    <span class="k">class</span><span class="w"> </span><span class="nc">scipy_wav</span><span class="p">:</span> 
        <span class="nd">@staticmethod</span>
        <span class="k">def</span><span class="w"> </span><span class="nf">write</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span> <span class="k">raise</span> <span class="ne">ImportError</span><span class="p">(</span><span class="s2">&quot;Scipy not installed, cannot write dummy audio.&quot;</span><span class="p">)</span>


<span class="k">try</span><span class="p">:</span>
    <span class="kn">import</span><span class="w"> </span><span class="nn">pytorchvideo.models</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">ptv_models_real</span> 
    <span class="kn">import</span><span class="w"> </span><span class="nn">pytorchvideo.transforms</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">ptv_transforms_real</span>
    <span class="kn">from</span><span class="w"> </span><span class="nn">pytorchvideo.data.encoded_video</span><span class="w"> </span><span class="kn">import</span> <span class="n">EncodedVideo</span> <span class="k">as</span> <span class="n">EncodedVideoReal</span>
    <span class="kn">import</span><span class="w"> </span><span class="nn">pytorchvideo.data.transforms</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">ptv_data_transforms_real</span>
    <span class="n">ptv_models</span> <span class="o">=</span> <span class="n">ptv_models_real</span>
    <span class="n">ptv_transforms</span> <span class="o">=</span> <span class="n">ptv_transforms_real</span>
    <span class="n">EncodedVideo</span> <span class="o">=</span> <span class="n">EncodedVideoReal</span>
    <span class="n">ptv_data_transforms</span> <span class="o">=</span> <span class="n">ptv_data_transforms_real</span>
<span class="k">except</span> <span class="ne">ImportError</span><span class="p">:</span>
    <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span>
        <span class="s2">&quot;PyTorchVideo library not found. Some video models (MViT, SlowFast) will not be available. &quot;</span>
        <span class="s2">&quot;Please install it: pip install pytorchvideo&quot;</span>
    <span class="p">)</span>
<div class="viewcode-block" id="ptv_models">
<a class="viewcode-back" href="../index.html#DLFeat.ptv_models">[docs]</a>
    <span class="k">class</span><span class="w"> </span><span class="nc">ptv_models</span><span class="p">:</span> 
<div class="viewcode-block" id="ptv_models.mvit">
<a class="viewcode-back" href="../index.html#DLFeat.ptv_models.mvit">[docs]</a>
        <span class="k">class</span><span class="w"> </span><span class="nc">mvit</span><span class="p">:</span> 
<div class="viewcode-block" id="ptv_models.mvit.create_mvit">
<a class="viewcode-back" href="../index.html#DLFeat.ptv_models.mvit.create_mvit">[docs]</a>
            <span class="nd">@staticmethod</span>
            <span class="k">def</span><span class="w"> </span><span class="nf">create_mvit</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>  <span class="k">raise</span> <span class="ne">ImportError</span><span class="p">(</span><span class="s2">&quot;PyTorchVideo not installed.&quot;</span><span class="p">)</span></div>
</div>

<div class="viewcode-block" id="ptv_models.i3d">
<a class="viewcode-back" href="../index.html#DLFeat.ptv_models.i3d">[docs]</a>
        <span class="k">class</span><span class="w"> </span><span class="nc">i3d</span><span class="p">:</span> 
<div class="viewcode-block" id="ptv_models.i3d.create_i3d">
<a class="viewcode-back" href="../index.html#DLFeat.ptv_models.i3d.create_i3d">[docs]</a>
            <span class="nd">@staticmethod</span>
            <span class="k">def</span><span class="w"> </span><span class="nf">create_i3d</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span> <span class="k">raise</span> <span class="ne">ImportError</span><span class="p">(</span><span class="s2">&quot;PyTorchVideo not installed.&quot;</span><span class="p">)</span></div>
</div>

<div class="viewcode-block" id="ptv_models.slowfast">
<a class="viewcode-back" href="../index.html#DLFeat.ptv_models.slowfast">[docs]</a>
        <span class="k">class</span><span class="w"> </span><span class="nc">slowfast</span><span class="p">:</span> 
<div class="viewcode-block" id="ptv_models.slowfast.create_slowfast">
<a class="viewcode-back" href="../index.html#DLFeat.ptv_models.slowfast.create_slowfast">[docs]</a>
             <span class="nd">@staticmethod</span>
             <span class="k">def</span><span class="w"> </span><span class="nf">create_slowfast</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span> <span class="k">raise</span> <span class="ne">ImportError</span><span class="p">(</span><span class="s2">&quot;PyTorchVideo not installed.&quot;</span><span class="p">)</span></div>
</div>
</div>

<div class="viewcode-block" id="ptv_transforms">
<a class="viewcode-back" href="../index.html#DLFeat.ptv_transforms">[docs]</a>
    <span class="k">class</span><span class="w"> </span><span class="nc">ptv_transforms</span><span class="p">:</span> <span class="k">pass</span> </div>

<div class="viewcode-block" id="EncodedVideo">
<a class="viewcode-back" href="../index.html#DLFeat.EncodedVideo">[docs]</a>
    <span class="k">class</span><span class="w"> </span><span class="nc">EncodedVideo</span><span class="p">:</span> <span class="k">pass</span> </div>

<div class="viewcode-block" id="ptv_data_transforms">
<a class="viewcode-back" href="../index.html#DLFeat.ptv_data_transforms">[docs]</a>
    <span class="k">class</span><span class="w"> </span><span class="nc">ptv_data_transforms</span><span class="p">:</span> <span class="k">pass</span> </div>



<span class="n">MODEL_CONFIGS</span> <span class="o">=</span> <span class="p">{</span>
    <span class="c1"># --- Image Models ---</span>
    <span class="s2">&quot;resnet18&quot;</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;task&quot;</span><span class="p">:</span> <span class="s2">&quot;image&quot;</span><span class="p">,</span> <span class="s2">&quot;dim&quot;</span><span class="p">:</span> <span class="mi">512</span><span class="p">,</span> <span class="s2">&quot;input_size&quot;</span><span class="p">:</span> <span class="mi">224</span><span class="p">,</span> <span class="s2">&quot;source&quot;</span><span class="p">:</span> <span class="s2">&quot;torchvision&quot;</span><span class="p">},</span>
    <span class="s2">&quot;resnet34&quot;</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;task&quot;</span><span class="p">:</span> <span class="s2">&quot;image&quot;</span><span class="p">,</span> <span class="s2">&quot;dim&quot;</span><span class="p">:</span> <span class="mi">512</span><span class="p">,</span> <span class="s2">&quot;input_size&quot;</span><span class="p">:</span> <span class="mi">224</span><span class="p">,</span> <span class="s2">&quot;source&quot;</span><span class="p">:</span> <span class="s2">&quot;torchvision&quot;</span><span class="p">},</span>
    <span class="s2">&quot;resnet50&quot;</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;task&quot;</span><span class="p">:</span> <span class="s2">&quot;image&quot;</span><span class="p">,</span> <span class="s2">&quot;dim&quot;</span><span class="p">:</span> <span class="mi">2048</span><span class="p">,</span> <span class="s2">&quot;input_size&quot;</span><span class="p">:</span> <span class="mi">224</span><span class="p">,</span> <span class="s2">&quot;source&quot;</span><span class="p">:</span> <span class="s2">&quot;torchvision_or_timm&quot;</span><span class="p">},</span>
    <span class="s2">&quot;resnet101&quot;</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;task&quot;</span><span class="p">:</span> <span class="s2">&quot;image&quot;</span><span class="p">,</span> <span class="s2">&quot;dim&quot;</span><span class="p">:</span> <span class="mi">2048</span><span class="p">,</span> <span class="s2">&quot;input_size&quot;</span><span class="p">:</span> <span class="mi">224</span><span class="p">,</span> <span class="s2">&quot;source&quot;</span><span class="p">:</span> <span class="s2">&quot;torchvision_or_timm&quot;</span><span class="p">},</span>
    <span class="s2">&quot;resnet152&quot;</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;task&quot;</span><span class="p">:</span> <span class="s2">&quot;image&quot;</span><span class="p">,</span> <span class="s2">&quot;dim&quot;</span><span class="p">:</span> <span class="mi">2048</span><span class="p">,</span> <span class="s2">&quot;input_size&quot;</span><span class="p">:</span> <span class="mi">224</span><span class="p">,</span> <span class="s2">&quot;source&quot;</span><span class="p">:</span> <span class="s2">&quot;torchvision_or_timm&quot;</span><span class="p">},</span>
    <span class="s2">&quot;efficientnet_b0&quot;</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;task&quot;</span><span class="p">:</span> <span class="s2">&quot;image&quot;</span><span class="p">,</span> <span class="s2">&quot;dim&quot;</span><span class="p">:</span> <span class="mi">1280</span><span class="p">,</span> <span class="s2">&quot;input_size&quot;</span><span class="p">:</span> <span class="mi">224</span><span class="p">,</span> <span class="s2">&quot;source&quot;</span><span class="p">:</span> <span class="s2">&quot;timm&quot;</span><span class="p">,</span> <span class="s2">&quot;timm_name&quot;</span><span class="p">:</span> <span class="s2">&quot;efficientnet_b0&quot;</span><span class="p">},</span>
    <span class="s2">&quot;efficientnet_b2&quot;</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;task&quot;</span><span class="p">:</span> <span class="s2">&quot;image&quot;</span><span class="p">,</span> <span class="s2">&quot;dim&quot;</span><span class="p">:</span> <span class="mi">1408</span><span class="p">,</span> <span class="s2">&quot;input_size&quot;</span><span class="p">:</span> <span class="mi">260</span><span class="p">,</span> <span class="s2">&quot;source&quot;</span><span class="p">:</span> <span class="s2">&quot;timm&quot;</span><span class="p">,</span> <span class="s2">&quot;timm_name&quot;</span><span class="p">:</span> <span class="s2">&quot;efficientnet_b2&quot;</span><span class="p">},</span>
    <span class="s2">&quot;efficientnet_b4&quot;</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;task&quot;</span><span class="p">:</span> <span class="s2">&quot;image&quot;</span><span class="p">,</span> <span class="s2">&quot;dim&quot;</span><span class="p">:</span> <span class="mi">1792</span><span class="p">,</span> <span class="s2">&quot;input_size&quot;</span><span class="p">:</span> <span class="mi">380</span><span class="p">,</span> <span class="s2">&quot;source&quot;</span><span class="p">:</span> <span class="s2">&quot;timm&quot;</span><span class="p">,</span> <span class="s2">&quot;timm_name&quot;</span><span class="p">:</span> <span class="s2">&quot;efficientnet_b4&quot;</span><span class="p">},</span>
    <span class="s2">&quot;mobilenet_v2&quot;</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;task&quot;</span><span class="p">:</span> <span class="s2">&quot;image&quot;</span><span class="p">,</span> <span class="s2">&quot;dim&quot;</span><span class="p">:</span> <span class="mi">1280</span><span class="p">,</span> <span class="s2">&quot;input_size&quot;</span><span class="p">:</span> <span class="mi">224</span><span class="p">,</span> <span class="s2">&quot;source&quot;</span><span class="p">:</span> <span class="s2">&quot;torchvision&quot;</span><span class="p">},</span>
    <span class="s2">&quot;mobilenet_v3_small&quot;</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;task&quot;</span><span class="p">:</span> <span class="s2">&quot;image&quot;</span><span class="p">,</span> <span class="s2">&quot;dim&quot;</span><span class="p">:</span> <span class="mi">576</span><span class="p">,</span> <span class="s2">&quot;input_size&quot;</span><span class="p">:</span> <span class="mi">224</span><span class="p">,</span> <span class="s2">&quot;source&quot;</span><span class="p">:</span> <span class="s2">&quot;torchvision&quot;</span><span class="p">},</span> 
    <span class="s2">&quot;mobilenet_v3_large&quot;</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;task&quot;</span><span class="p">:</span> <span class="s2">&quot;image&quot;</span><span class="p">,</span> <span class="s2">&quot;dim&quot;</span><span class="p">:</span> <span class="mi">960</span><span class="p">,</span> <span class="s2">&quot;input_size&quot;</span><span class="p">:</span> <span class="mi">224</span><span class="p">,</span> <span class="s2">&quot;source&quot;</span><span class="p">:</span> <span class="s2">&quot;torchvision&quot;</span><span class="p">},</span> 
    <span class="s2">&quot;vit_tiny_patch16_224&quot;</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;task&quot;</span><span class="p">:</span> <span class="s2">&quot;image&quot;</span><span class="p">,</span> <span class="s2">&quot;dim&quot;</span><span class="p">:</span> <span class="mi">192</span><span class="p">,</span> <span class="s2">&quot;input_size&quot;</span><span class="p">:</span> <span class="mi">224</span><span class="p">,</span> <span class="s2">&quot;source&quot;</span><span class="p">:</span> <span class="s2">&quot;timm&quot;</span><span class="p">,</span> <span class="s2">&quot;timm_name&quot;</span><span class="p">:</span> <span class="s2">&quot;vit_tiny_patch16_224.augreg_in21k_ft_in1k&quot;</span><span class="p">},</span> 
    <span class="s2">&quot;vit_small_patch16_224&quot;</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;task&quot;</span><span class="p">:</span> <span class="s2">&quot;image&quot;</span><span class="p">,</span> <span class="s2">&quot;dim&quot;</span><span class="p">:</span> <span class="mi">384</span><span class="p">,</span> <span class="s2">&quot;input_size&quot;</span><span class="p">:</span> <span class="mi">224</span><span class="p">,</span> <span class="s2">&quot;source&quot;</span><span class="p">:</span> <span class="s2">&quot;timm&quot;</span><span class="p">,</span> <span class="s2">&quot;timm_name&quot;</span><span class="p">:</span> <span class="s2">&quot;vit_small_patch16_224.augreg_in21k_ft_in1k&quot;</span><span class="p">},</span>
    <span class="s2">&quot;vit_base_patch16_224&quot;</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;task&quot;</span><span class="p">:</span> <span class="s2">&quot;image&quot;</span><span class="p">,</span> <span class="s2">&quot;dim&quot;</span><span class="p">:</span> <span class="mi">768</span><span class="p">,</span> <span class="s2">&quot;input_size&quot;</span><span class="p">:</span> <span class="mi">224</span><span class="p">,</span> <span class="s2">&quot;source&quot;</span><span class="p">:</span> <span class="s2">&quot;timm&quot;</span><span class="p">,</span> <span class="s2">&quot;timm_name&quot;</span><span class="p">:</span> <span class="s2">&quot;vit_base_patch16_224.mae&quot;</span><span class="p">},</span> 
    <span class="s2">&quot;dinov2_base&quot;</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;task&quot;</span><span class="p">:</span> <span class="s2">&quot;image&quot;</span><span class="p">,</span> <span class="s2">&quot;dim&quot;</span><span class="p">:</span> <span class="mi">768</span><span class="p">,</span> <span class="s2">&quot;input_size&quot;</span><span class="p">:</span> <span class="mi">224</span><span class="p">,</span> <span class="s2">&quot;source&quot;</span><span class="p">:</span> <span class="s2">&quot;transformers&quot;</span><span class="p">,</span> <span class="s2">&quot;hf_name&quot;</span><span class="p">:</span> <span class="s2">&quot;facebook/dinov2-base&quot;</span><span class="p">},</span>

    <span class="c1"># --- Video Models ---</span>
    <span class="s2">&quot;r2plus1d_18&quot;</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;task&quot;</span><span class="p">:</span> <span class="s2">&quot;video&quot;</span><span class="p">,</span> <span class="s2">&quot;dim&quot;</span><span class="p">:</span> <span class="mi">512</span><span class="p">,</span> <span class="s2">&quot;source&quot;</span><span class="p">:</span> <span class="s2">&quot;torchvision&quot;</span><span class="p">,</span> <span class="s2">&quot;tv_model_name&quot;</span><span class="p">:</span><span class="s2">&quot;r2plus1d_18&quot;</span><span class="p">,</span> <span class="s2">&quot;clip_len&quot;</span><span class="p">:</span> <span class="mi">16</span><span class="p">,</span> <span class="s2">&quot;frame_rate&quot;</span><span class="p">:</span> <span class="mi">15</span><span class="p">,</span> <span class="s2">&quot;input_size&quot;</span><span class="p">:</span> <span class="mi">112</span><span class="p">},</span> 
    <span class="s2">&quot;videomae_base_k400_pt&quot;</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;task&quot;</span><span class="p">:</span> <span class="s2">&quot;video&quot;</span><span class="p">,</span> <span class="s2">&quot;dim&quot;</span><span class="p">:</span> <span class="mi">768</span><span class="p">,</span> <span class="s2">&quot;source&quot;</span><span class="p">:</span> <span class="s2">&quot;transformers&quot;</span><span class="p">,</span> <span class="s2">&quot;hf_name&quot;</span><span class="p">:</span> <span class="s2">&quot;MCG-NJU/videomae-base-finetuned-kinetics&quot;</span><span class="p">,</span> <span class="s2">&quot;num_frames&quot;</span><span class="p">:</span> <span class="mi">16</span><span class="p">,</span> <span class="s2">&quot;input_size&quot;</span><span class="p">:</span> <span class="mi">224</span><span class="p">},</span>
    <span class="s2">&quot;mvit_v2_s&quot;</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;task&quot;</span><span class="p">:</span> <span class="s2">&quot;video&quot;</span><span class="p">,</span> <span class="s2">&quot;dim&quot;</span><span class="p">:</span> <span class="mi">768</span><span class="p">,</span> <span class="s2">&quot;source&quot;</span><span class="p">:</span> <span class="s2">&quot;pytorchvideo&quot;</span><span class="p">,</span> <span class="s2">&quot;clip_len&quot;</span><span class="p">:</span> <span class="mi">32</span><span class="p">,</span> <span class="s2">&quot;frame_rate&quot;</span><span class="p">:</span> <span class="mi">3</span><span class="p">,</span> <span class="s2">&quot;input_size&quot;</span><span class="p">:</span> <span class="mi">224</span><span class="p">,</span> <span class="s2">&quot;ptv_hub_name&quot;</span><span class="p">:</span> <span class="s2">&quot;mvit_v2_s_32x3_kinetics400_strid&quot;</span><span class="p">},</span>
    <span class="s2">&quot;slowfast_r50&quot;</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;task&quot;</span><span class="p">:</span> <span class="s2">&quot;video&quot;</span><span class="p">,</span> <span class="s2">&quot;dim&quot;</span><span class="p">:</span> <span class="mi">2304</span><span class="p">,</span> <span class="s2">&quot;source&quot;</span><span class="p">:</span> <span class="s2">&quot;pytorchvideo&quot;</span><span class="p">,</span> <span class="s2">&quot;clip_len&quot;</span><span class="p">:</span> <span class="mi">32</span><span class="p">,</span> <span class="s2">&quot;frame_rate_alpha&quot;</span><span class="p">:</span> <span class="mi">4</span><span class="p">,</span> <span class="s2">&quot;input_size&quot;</span><span class="p">:</span> <span class="mi">256</span><span class="p">,</span> <span class="s2">&quot;ptv_hub_name&quot;</span><span class="p">:</span> <span class="s2">&quot;slowfast_r50&quot;</span><span class="p">},</span> <span class="c1"># Using standard slowfast_r50 from PTV hub</span>
    <span class="s2">&quot;tsm_resnet50&quot;</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;task&quot;</span><span class="p">:</span> <span class="s2">&quot;video&quot;</span><span class="p">,</span> <span class="s2">&quot;dim&quot;</span><span class="p">:</span> <span class="mi">2048</span><span class="p">,</span> <span class="s2">&quot;source&quot;</span><span class="p">:</span> <span class="s2">&quot;timm&quot;</span><span class="p">,</span> <span class="s2">&quot;timm_name&quot;</span><span class="p">:</span> <span class="s2">&quot;tsm_resnet50&quot;</span><span class="p">,</span> <span class="s2">&quot;num_frames&quot;</span><span class="p">:</span> <span class="mi">8</span><span class="p">,</span> <span class="s2">&quot;input_size&quot;</span><span class="p">:</span> <span class="mi">224</span><span class="p">},</span> 
    <span class="s2">&quot;video_swin_t&quot;</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;task&quot;</span><span class="p">:</span> <span class="s2">&quot;video&quot;</span><span class="p">,</span> <span class="s2">&quot;dim&quot;</span><span class="p">:</span> <span class="mi">768</span><span class="p">,</span> <span class="s2">&quot;source&quot;</span><span class="p">:</span> <span class="s2">&quot;torchvision&quot;</span><span class="p">,</span> <span class="s2">&quot;tv_model_name&quot;</span><span class="p">:</span> <span class="s2">&quot;swin_t&quot;</span><span class="p">,</span> <span class="s2">&quot;clip_len&quot;</span><span class="p">:</span> <span class="mi">32</span><span class="p">,</span> <span class="s2">&quot;input_size&quot;</span><span class="p">:</span> <span class="mi">224</span><span class="p">},</span>
    <span class="s2">&quot;video_swin_s&quot;</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;task&quot;</span><span class="p">:</span> <span class="s2">&quot;video&quot;</span><span class="p">,</span> <span class="s2">&quot;dim&quot;</span><span class="p">:</span> <span class="mi">768</span><span class="p">,</span> <span class="s2">&quot;source&quot;</span><span class="p">:</span> <span class="s2">&quot;torchvision&quot;</span><span class="p">,</span> <span class="s2">&quot;tv_model_name&quot;</span><span class="p">:</span> <span class="s2">&quot;swin_s&quot;</span><span class="p">,</span> <span class="s2">&quot;clip_len&quot;</span><span class="p">:</span> <span class="mi">32</span><span class="p">,</span> <span class="s2">&quot;input_size&quot;</span><span class="p">:</span> <span class="mi">224</span><span class="p">},</span>
    <span class="s2">&quot;video_swin_b&quot;</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;task&quot;</span><span class="p">:</span> <span class="s2">&quot;video&quot;</span><span class="p">,</span> <span class="s2">&quot;dim&quot;</span><span class="p">:</span> <span class="mi">1024</span><span class="p">,</span> <span class="s2">&quot;source&quot;</span><span class="p">:</span> <span class="s2">&quot;torchvision&quot;</span><span class="p">,</span> <span class="s2">&quot;tv_model_name&quot;</span><span class="p">:</span> <span class="s2">&quot;swin_b&quot;</span><span class="p">,</span> <span class="s2">&quot;clip_len&quot;</span><span class="p">:</span> <span class="mi">32</span><span class="p">,</span> <span class="s2">&quot;input_size&quot;</span><span class="p">:</span> <span class="mi">224</span><span class="p">},</span>
    
    <span class="c1"># --- Audio Models ---</span>
    <span class="s2">&quot;wav2vec2_base&quot;</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;task&quot;</span><span class="p">:</span> <span class="s2">&quot;audio&quot;</span><span class="p">,</span> <span class="s2">&quot;dim&quot;</span><span class="p">:</span> <span class="mi">768</span><span class="p">,</span> <span class="s2">&quot;source&quot;</span><span class="p">:</span> <span class="s2">&quot;transformers&quot;</span><span class="p">,</span> <span class="s2">&quot;hf_name&quot;</span><span class="p">:</span> <span class="s2">&quot;facebook/wav2vec2-base-960h&quot;</span><span class="p">,</span> <span class="s2">&quot;sampling_rate&quot;</span><span class="p">:</span> <span class="mi">16000</span><span class="p">},</span>
    <span class="s2">&quot;ast_vit_base_patch16_224&quot;</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;task&quot;</span><span class="p">:</span> <span class="s2">&quot;audio&quot;</span><span class="p">,</span> <span class="s2">&quot;dim&quot;</span><span class="p">:</span> <span class="mi">768</span><span class="p">,</span> <span class="s2">&quot;source&quot;</span><span class="p">:</span> <span class="s2">&quot;transformers&quot;</span><span class="p">,</span> <span class="s2">&quot;hf_name&quot;</span><span class="p">:</span> <span class="s2">&quot;MIT/ast-finetuned-audioset-10-10-0.4593&quot;</span><span class="p">,</span> <span class="s2">&quot;sampling_rate&quot;</span><span class="p">:</span> <span class="mi">16000</span><span class="p">,</span> <span class="s2">&quot;num_mel_bins&quot;</span><span class="p">:</span> <span class="mi">128</span><span class="p">,</span> <span class="s2">&quot;max_length_s&quot;</span><span class="p">:</span> <span class="mf">10.24</span><span class="p">},</span>

    <span class="c1"># --- Text Models ---</span>
    <span class="s2">&quot;sentence-bert&quot;</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;task&quot;</span><span class="p">:</span> <span class="s2">&quot;text&quot;</span><span class="p">,</span> <span class="s2">&quot;dim&quot;</span><span class="p">:</span> <span class="mi">384</span><span class="p">,</span> <span class="s2">&quot;source&quot;</span><span class="p">:</span> <span class="s2">&quot;sentence-transformers&quot;</span><span class="p">,</span> <span class="s2">&quot;st_name&quot;</span><span class="p">:</span> <span class="s2">&quot;all-MiniLM-L6-v2&quot;</span><span class="p">},</span>
    <span class="s2">&quot;bert_base_uncased&quot;</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;task&quot;</span><span class="p">:</span> <span class="s2">&quot;text&quot;</span><span class="p">,</span> <span class="s2">&quot;dim&quot;</span><span class="p">:</span> <span class="mi">768</span><span class="p">,</span> <span class="s2">&quot;source&quot;</span><span class="p">:</span> <span class="s2">&quot;transformers&quot;</span><span class="p">,</span> <span class="s2">&quot;hf_name&quot;</span><span class="p">:</span> <span class="s2">&quot;bert-base-uncased&quot;</span><span class="p">},</span>

    <span class="c1"># --- Multimodal Models ---</span>
    <span class="s2">&quot;clip_vit_b32&quot;</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;task&quot;</span><span class="p">:</span> <span class="s2">&quot;multimodal_image_text&quot;</span><span class="p">,</span> <span class="s2">&quot;dim&quot;</span><span class="p">:</span> <span class="mi">512</span><span class="p">,</span> <span class="s2">&quot;source&quot;</span><span class="p">:</span> <span class="s2">&quot;transformers&quot;</span><span class="p">,</span> <span class="s2">&quot;hf_name&quot;</span><span class="p">:</span> <span class="s2">&quot;openai/clip-vit-base-patch32&quot;</span><span class="p">},</span>
    <span class="s2">&quot;xclip_base_patch16&quot;</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;task&quot;</span><span class="p">:</span> <span class="s2">&quot;multimodal_video_text&quot;</span><span class="p">,</span> <span class="s2">&quot;dim&quot;</span><span class="p">:</span> <span class="mi">512</span><span class="p">,</span> <span class="s2">&quot;source&quot;</span><span class="p">:</span> <span class="s2">&quot;transformers&quot;</span><span class="p">,</span> <span class="s2">&quot;hf_name&quot;</span><span class="p">:</span> <span class="s2">&quot;microsoft/xclip-base-patch16&quot;</span><span class="p">,</span> <span class="s2">&quot;num_frames&quot;</span><span class="p">:</span> <span class="mi">8</span><span class="p">}</span>
<span class="p">}</span>

<span class="n">DEFAULT_MODELS_TO_TEST</span> <span class="o">=</span> <span class="p">[</span>
    <span class="s2">&quot;resnet18&quot;</span><span class="p">,</span> <span class="s2">&quot;efficientnet_b0&quot;</span><span class="p">,</span> <span class="s2">&quot;mobilenet_v2&quot;</span><span class="p">,</span> <span class="s2">&quot;vit_tiny_patch16_224&quot;</span><span class="p">,</span> <span class="s2">&quot;dinov2_base&quot;</span><span class="p">,</span>
    <span class="s2">&quot;r2plus1d_18&quot;</span><span class="p">,</span> <span class="s2">&quot;videomae_base_k400_pt&quot;</span><span class="p">,</span> <span class="s2">&quot;mvit_v2_s&quot;</span><span class="p">,</span> <span class="s2">&quot;slowfast_r50&quot;</span><span class="p">,</span> <span class="s2">&quot;tsm_resnet50&quot;</span><span class="p">,</span> <span class="s2">&quot;video_swin_t&quot;</span><span class="p">,</span>
    <span class="s2">&quot;wav2vec2_base&quot;</span><span class="p">,</span> <span class="s2">&quot;sentence-bert&quot;</span><span class="p">,</span> 
    <span class="s2">&quot;clip_vit_b32&quot;</span><span class="p">,</span> <span class="s2">&quot;xclip_base_patch16&quot;</span>
<span class="p">]</span>


<div class="viewcode-block" id="list_available_models">
<a class="viewcode-back" href="../index.html#DLFeat.list_available_models">[docs]</a>
<span class="k">def</span><span class="w"> </span><span class="nf">list_available_models</span><span class="p">(</span><span class="n">task_type</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="c1"># ... (same as v0.2.9) ...</span>
    <span class="k">if</span> <span class="n">task_type</span><span class="p">:</span>
        <span class="k">return</span> <span class="p">[</span><span class="n">name</span> <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">config</span> <span class="ow">in</span> <span class="n">MODEL_CONFIGS</span><span class="o">.</span><span class="n">items</span><span class="p">()</span> <span class="k">if</span> <span class="n">config</span><span class="p">[</span><span class="s2">&quot;task&quot;</span><span class="p">]</span> <span class="o">==</span> <span class="n">task_type</span><span class="p">]</span>
    <span class="k">return</span> <span class="nb">list</span><span class="p">(</span><span class="n">MODEL_CONFIGS</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span></div>



<div class="viewcode-block" id="DLFeatExtractor">
<a class="viewcode-back" href="../index.html#DLFeat.DLFeatExtractor">[docs]</a>
<span class="k">class</span><span class="w"> </span><span class="nc">DLFeatExtractor</span><span class="p">(</span><span class="n">BaseEstimator</span><span class="p">,</span> <span class="n">TransformerMixin</span><span class="p">):</span>
    <span class="c1"># ... (Constructor, get_feature_dimension, get_model_config same as v0.2.9) ...</span>
<div class="viewcode-block" id="DLFeatExtractor.__init__">
<a class="viewcode-back" href="../index.html#DLFeat.DLFeatExtractor.__init__">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model_name</span><span class="p">,</span> <span class="n">task_type</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="s2">&quot;auto&quot;</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">model_name</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">MODEL_CONFIGS</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;Model &#39;</span><span class="si">{</span><span class="n">model_name</span><span class="si">}</span><span class="s2">&#39; not found. &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;Available models: </span><span class="si">{</span><span class="n">list_available_models</span><span class="p">()</span><span class="si">}</span><span class="s2">&quot;</span>
            <span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">model_name</span> <span class="o">=</span> <span class="n">model_name</span> 
        <span class="bp">self</span><span class="o">.</span><span class="n">config</span> <span class="o">=</span> <span class="n">MODEL_CONFIGS</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">model_name</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">task_type</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s2">&quot;task&quot;</span><span class="p">]</span>

        <span class="k">if</span> <span class="n">task_type</span> <span class="ow">and</span> <span class="n">task_type</span> <span class="o">!=</span> <span class="bp">self</span><span class="o">.</span><span class="n">task_type</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;Provided task_type &#39;</span><span class="si">{</span><span class="n">task_type</span><span class="si">}</span><span class="s2">&#39; does not match model &#39;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">model_name</span><span class="si">}</span><span class="s2">&#39;s task &#39;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">task_type</span><span class="si">}</span><span class="s2">&#39;.&quot;</span>
            <span class="p">)</span>

        <span class="k">if</span> <span class="n">device</span> <span class="o">==</span> <span class="s2">&quot;auto&quot;</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">():</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">&quot;cuda&quot;</span><span class="p">)</span>
            <span class="k">elif</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">backends</span><span class="p">,</span> <span class="s1">&#39;mps&#39;</span><span class="p">)</span> <span class="ow">and</span> <span class="n">torch</span><span class="o">.</span><span class="n">backends</span><span class="o">.</span><span class="n">mps</span><span class="o">.</span><span class="n">is_available</span><span class="p">():</span> 
                <span class="bp">self</span><span class="o">.</span><span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">&quot;mps&quot;</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">&quot;cpu&quot;</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">processor</span> <span class="o">=</span> <span class="kc">None</span> 
        <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span> <span class="o">=</span> <span class="kc">None</span> 
        <span class="bp">self</span><span class="o">.</span><span class="n">image_transform</span> <span class="o">=</span> <span class="kc">None</span> 
        <span class="bp">self</span><span class="o">.</span><span class="n">audio_resampler</span> <span class="o">=</span> <span class="kc">None</span> 
        <span class="bp">self</span><span class="o">.</span><span class="n">video_frame_transform</span> <span class="o">=</span> <span class="kc">None</span> <span class="c1"># Explicitly initialize for video</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">video_transform_params</span> <span class="o">=</span> <span class="kc">None</span> 
        <span class="bp">self</span><span class="o">.</span><span class="n">target_sr</span> <span class="o">=</span> <span class="kc">None</span> 

        <span class="bp">self</span><span class="o">.</span><span class="n">_load_model</span><span class="p">()</span></div>


<div class="viewcode-block" id="DLFeatExtractor.get_feature_dimension">
<a class="viewcode-back" href="../index.html#DLFeat.DLFeatExtractor.get_feature_dimension">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">get_feature_dimension</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s2">&quot;dim&quot;</span><span class="p">]</span></div>


<div class="viewcode-block" id="DLFeatExtractor.get_model_config">
<a class="viewcode-back" href="../index.html#DLFeat.DLFeatExtractor.get_model_config">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">get_model_config</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span></div>


    <span class="k">def</span><span class="w"> </span><span class="nf">_load_image_model_torchvision</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model_name_tv</span><span class="p">):</span>
        <span class="c1"># ... (same as v0.2.9)</span>
        <span class="n">model_fn</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">tv_models</span><span class="p">,</span> <span class="n">model_name_tv</span><span class="p">)</span>
        
        <span class="n">weights_enum_name_to_try</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="k">if</span> <span class="n">model_name_tv</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s2">&quot;resnet&quot;</span><span class="p">):</span>
            <span class="n">name_part</span> <span class="o">=</span> <span class="n">model_name_tv</span><span class="p">[</span><span class="nb">len</span><span class="p">(</span><span class="s2">&quot;resnet&quot;</span><span class="p">):]</span> 
            <span class="n">weights_enum_name_to_try</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;ResNet</span><span class="si">{</span><span class="n">name_part</span><span class="si">}</span><span class="s2">_Weights&quot;</span> 
        <span class="k">elif</span> <span class="n">model_name_tv</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s2">&quot;vgg&quot;</span><span class="p">):</span> 
            <span class="n">weights_enum_name_to_try</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">model_name_tv</span><span class="o">.</span><span class="n">upper</span><span class="p">()</span><span class="si">}</span><span class="s2">_Weights&quot;</span>
        <span class="k">elif</span> <span class="n">model_name_tv</span> <span class="o">==</span> <span class="s2">&quot;mobilenet_v2&quot;</span><span class="p">:</span> 
             <span class="n">weights_enum_name_to_try</span> <span class="o">=</span> <span class="s2">&quot;MobileNet_V2_Weights&quot;</span>
        <span class="k">elif</span> <span class="n">model_name_tv</span> <span class="o">==</span> <span class="s2">&quot;mobilenet_v3_large&quot;</span><span class="p">:</span> 
             <span class="n">weights_enum_name_to_try</span> <span class="o">=</span> <span class="s2">&quot;MobileNet_V3_Large_Weights&quot;</span>
        <span class="k">elif</span> <span class="n">model_name_tv</span> <span class="o">==</span> <span class="s2">&quot;mobilenet_v3_small&quot;</span><span class="p">:</span> 
             <span class="n">weights_enum_name_to_try</span> <span class="o">=</span> <span class="s2">&quot;MobileNet_V3_Small_Weights&quot;</span>
        <span class="k">elif</span> <span class="n">model_name_tv</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s2">&quot;efficientnet_b&quot;</span><span class="p">):</span> <span class="c1"># Not typically loaded from torchvision by DLFeat, but for completeness</span>
            <span class="n">name_part</span> <span class="o">=</span> <span class="n">model_name_tv</span><span class="p">[</span><span class="nb">len</span><span class="p">(</span><span class="s2">&quot;efficientnet_&quot;</span><span class="p">):]</span> 
            <span class="n">weights_enum_name_to_try</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;EfficientNet_</span><span class="si">{</span><span class="n">name_part</span><span class="o">.</span><span class="n">upper</span><span class="p">()</span><span class="si">}</span><span class="s2">_Weights&quot;</span> 
        <span class="k">elif</span> <span class="n">model_name_tv</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s2">&quot;convnext_&quot;</span><span class="p">):</span> <span class="c1"># Not typically loaded from torchvision by DLFeat</span>
            <span class="n">name_part</span> <span class="o">=</span> <span class="n">model_name_tv</span><span class="p">[</span><span class="nb">len</span><span class="p">(</span><span class="s2">&quot;convnext_&quot;</span><span class="p">):]</span> 
            <span class="n">weights_enum_name_to_try</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;ConvNeXt_</span><span class="si">{</span><span class="n">name_part</span><span class="o">.</span><span class="n">capitalize</span><span class="p">()</span><span class="si">}</span><span class="s2">_Weights&quot;</span> 
        <span class="k">else</span><span class="p">:</span>
            <span class="n">weights_enum_name_to_try</span> <span class="o">=</span> <span class="n">model_name_tv</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">upper</span><span class="p">()</span> <span class="o">+</span> <span class="n">model_name_tv</span><span class="p">[</span><span class="mi">1</span><span class="p">:]</span> <span class="o">+</span> <span class="s2">&quot;_Weights&quot;</span>

        <span class="k">try</span><span class="p">:</span>
            <span class="n">weights_class</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">tv_models</span><span class="p">,</span> <span class="n">weights_enum_name_to_try</span><span class="p">)</span>
            
            <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">weights_class</span><span class="p">,</span> <span class="s1">&#39;DEFAULT&#39;</span><span class="p">):</span>
                <span class="n">weights_obj</span> <span class="o">=</span> <span class="n">weights_class</span><span class="o">.</span><span class="n">DEFAULT</span>
            <span class="k">elif</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">weights_class</span><span class="p">,</span> <span class="s1">&#39;IMAGENET1K_V1&#39;</span><span class="p">):</span> 
                <span class="n">weights_obj</span> <span class="o">=</span> <span class="n">weights_class</span><span class="o">.</span><span class="n">IMAGENET1K_V1</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">available_enum_members</span> <span class="o">=</span> <span class="p">[</span><span class="n">m</span> <span class="k">for</span> <span class="n">m</span> <span class="ow">in</span> <span class="nb">dir</span><span class="p">(</span><span class="n">weights_class</span><span class="p">)</span> <span class="k">if</span> <span class="ow">not</span> <span class="n">m</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s1">&#39;_&#39;</span><span class="p">)</span> <span class="ow">and</span> <span class="n">m</span><span class="o">.</span><span class="n">isupper</span><span class="p">()]</span>
                <span class="k">if</span> <span class="n">available_enum_members</span><span class="p">:</span>
                    <span class="n">first_available_weight_name</span> <span class="o">=</span> <span class="n">available_enum_members</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
                    <span class="n">weights_obj</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">weights_class</span><span class="p">,</span> <span class="n">first_available_weight_name</span><span class="p">)</span>
                    <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;DLFeatExtractor: Using first available weight &#39;</span><span class="si">{</span><span class="n">first_available_weight_name</span><span class="si">}</span><span class="s2">&#39; for </span><span class="si">{</span><span class="n">model_name_tv</span><span class="si">}</span><span class="s2"> as DEFAULT/IMAGENET1K_V1 not found in its enum.&quot;</span><span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="k">raise</span> <span class="ne">AttributeError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;No DEFAULT, IMAGENET1K_V1, or other suitable weights found in </span><span class="si">{</span><span class="n">weights_enum_name_to_try</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            
            <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">model_fn</span><span class="p">(</span><span class="n">weights</span><span class="o">=</span><span class="n">weights_obj</span><span class="p">)</span>
            <span class="c1"># Store transforms from weights if available for image models too</span>
            <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">weights_obj</span><span class="p">,</span> <span class="s1">&#39;transforms&#39;</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">callable</span><span class="p">(</span><span class="n">weights_obj</span><span class="o">.</span><span class="n">transforms</span><span class="p">):</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">image_transform</span> <span class="o">=</span> <span class="n">weights_obj</span><span class="o">.</span><span class="n">transforms</span><span class="p">()</span>

        <span class="k">except</span> <span class="p">(</span><span class="ne">AttributeError</span><span class="p">,</span> <span class="ne">ValueError</span><span class="p">)</span> <span class="k">as</span> <span class="n">e_new_api_img</span><span class="p">:</span> 
            <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;DLFeatExtractor: Failed to use new &#39;weights&#39; API for image model </span><span class="si">{</span><span class="n">model_name_tv</span><span class="si">}</span><span class="s2"> (Error: </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">e_new_api_img</span><span class="p">)</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">e_new_api_img</span><span class="si">}</span><span class="s2">). &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;Falling back to legacy &#39;pretrained=True&#39;. Torchvision warnings may follow.&quot;</span>
            <span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">model_fn</span><span class="p">(</span><span class="n">pretrained</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
             
        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="s1">&#39;classifier&#39;</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">classifier</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">classifier</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="p">:</span>
             <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">classifier</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Identity</span><span class="p">()</span>
        <span class="k">elif</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="s1">&#39;fc&#39;</span><span class="p">):</span> 
            <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">fc</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Identity</span><span class="p">()</span>
        <span class="k">elif</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="s1">&#39;classifier&#39;</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">classifier</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">):</span> 
            <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">classifier</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Identity</span><span class="p">()</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
        
        <span class="c1"># If transforms weren&#39;t set from weights, set default</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">image_transform</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">input_size</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;input_size&quot;</span><span class="p">,</span> <span class="mi">224</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">image_transform</span> <span class="o">=</span> <span class="n">T</span><span class="o">.</span><span class="n">Compose</span><span class="p">([</span>
                <span class="n">T</span><span class="o">.</span><span class="n">Resize</span><span class="p">(</span><span class="mi">256</span> <span class="k">if</span> <span class="n">input_size</span> <span class="o">==</span> <span class="mi">224</span> <span class="k">else</span> <span class="nb">int</span><span class="p">(</span><span class="n">input_size</span> <span class="o">/</span> <span class="p">(</span><span class="mf">224.0</span><span class="o">/</span><span class="mf">256.0</span><span class="p">))),</span> <span class="c1"># Maintain aspect ratio for resize then crop</span>
                <span class="n">T</span><span class="o">.</span><span class="n">CenterCrop</span><span class="p">(</span><span class="n">input_size</span><span class="p">),</span>
                <span class="n">T</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">(),</span>
                <span class="n">T</span><span class="o">.</span><span class="n">Normalize</span><span class="p">(</span><span class="n">mean</span><span class="o">=</span><span class="p">[</span><span class="mf">0.485</span><span class="p">,</span> <span class="mf">0.456</span><span class="p">,</span> <span class="mf">0.406</span><span class="p">],</span> <span class="n">std</span><span class="o">=</span><span class="p">[</span><span class="mf">0.229</span><span class="p">,</span> <span class="mf">0.224</span><span class="p">,</span> <span class="mf">0.225</span><span class="p">]),</span>
            <span class="p">])</span>
        <span class="c1"># Ensure the loaded transform&#39;s crop size matches config if possible</span>
        <span class="k">elif</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">image_transform</span><span class="p">,</span> <span class="s1">&#39;crop_size&#39;</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">image_transform</span><span class="o">.</span><span class="n">crop_size</span><span class="p">,</span> <span class="nb">int</span><span class="p">)</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">image_transform</span><span class="o">.</span><span class="n">crop_size</span> <span class="o">!=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;input_size&quot;</span><span class="p">,</span> <span class="mi">224</span><span class="p">):</span>
            <span class="n">new_input_size</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;input_size&quot;</span><span class="p">,</span> <span class="mi">224</span><span class="p">)</span>
            <span class="c1"># This is tricky as transforms object is already composed. Modifying it directly can be error prone.</span>
            <span class="c1"># For now, we assume the transforms() from weights are mostly correct for the pretrained model.</span>
            <span class="c1"># If a specific input_size is mandated by DLFeat config AND different from default weight&#39;s transform,</span>
            <span class="c1"># it might indicate a mismatch or need for custom transform chain.</span>
            <span class="c1"># Current logic: if self.image_transform is set, we use it as is.</span>
            <span class="k">pass</span>


    <span class="k">def</span><span class="w"> </span><span class="nf">_load_image_model_timm</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">timm_model_name</span><span class="p">):</span>
        <span class="c1"># ... (same as v0.2.9)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">timm</span><span class="p">,</span> <span class="s1">&#39;create_model&#39;</span><span class="p">):</span> 
             <span class="k">raise</span> <span class="ne">ImportError</span><span class="p">(</span><span class="s2">&quot;TIMM library is not installed. Please install it: pip install timm&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">timm</span><span class="o">.</span><span class="n">create_model</span><span class="p">(</span><span class="n">timm_model_name</span><span class="p">,</span> <span class="n">pretrained</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">num_classes</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
        <span class="n">data_config</span> <span class="o">=</span> <span class="n">timm</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">resolve_data_config</span><span class="p">({},</span> <span class="n">model</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">image_transform</span> <span class="o">=</span> <span class="n">timm</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">create_transform</span><span class="p">(</span><span class="o">**</span><span class="n">data_config</span><span class="p">)</span>
        <span class="k">if</span> <span class="s2">&quot;input_size&quot;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">:</span> 
            <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s2">&quot;input_size&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">data_config</span><span class="p">[</span><span class="s1">&#39;input_size&#39;</span><span class="p">][</span><span class="mi">1</span><span class="p">]</span> 

    <span class="k">def</span><span class="w"> </span><span class="nf">_load_image_model_dinov2</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="c1"># ... (same as v0.2.9)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">Dinov2Model</span><span class="p">,</span> <span class="s1">&#39;from_pretrained&#39;</span><span class="p">)</span> <span class="ow">or</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">AutoImageProcessor</span><span class="p">,</span> <span class="s1">&#39;from_pretrained&#39;</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">ImportError</span><span class="p">(</span>
                <span class="s2">&quot;Transformers components (Dinov2Model or AutoImageProcessor) not available or are dummy classes. &quot;</span>
                <span class="s2">&quot;Update transformers: pip install --upgrade transformers&quot;</span>
            <span class="p">)</span>
        <span class="n">hf_name</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s2">&quot;hf_name&quot;</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">processor</span> <span class="o">=</span> <span class="n">AutoImageProcessor</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">hf_name</span><span class="p">)</span> 
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">Dinov2Model</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">hf_name</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>


    <span class="k">def</span><span class="w"> </span><span class="nf">_load_model</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">source</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s2">&quot;source&quot;</span><span class="p">]</span>
        <span class="c1"># Clear any pre-existing video frame transform before loading a new model</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">video_frame_transform</span> <span class="o">=</span> <span class="kc">None</span> 

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">task_type</span> <span class="o">==</span> <span class="s2">&quot;image&quot;</span><span class="p">:</span>
            <span class="c1"># ... (image loading logic as in v0.2.9)</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_name</span> <span class="o">==</span> <span class="s2">&quot;dinov2_base&quot;</span><span class="p">:</span> 
                <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">Dinov2Model</span><span class="p">,</span> <span class="s1">&#39;from_pretrained&#39;</span><span class="p">):</span> 
                    <span class="k">raise</span> <span class="ne">ImportError</span><span class="p">(</span><span class="s2">&quot;Transformers (Dinov2Model) dummy class detected or not installed.&quot;</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_load_image_model_dinov2</span><span class="p">()</span> 
            <span class="k">elif</span> <span class="n">source</span> <span class="o">==</span> <span class="s2">&quot;torchvision&quot;</span><span class="p">:</span> 
                <span class="bp">self</span><span class="o">.</span><span class="n">_load_image_model_torchvision</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model_name</span><span class="p">)</span>
            <span class="k">elif</span> <span class="n">source</span> <span class="o">==</span> <span class="s2">&quot;torchvision_or_timm&quot;</span><span class="p">:</span>
                <span class="k">try</span><span class="p">:</span>
                    <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">timm</span><span class="p">,</span> <span class="s1">&#39;create_model&#39;</span><span class="p">):</span> <span class="k">raise</span> <span class="ne">ImportError</span><span class="p">(</span><span class="s2">&quot;TIMM not available&quot;</span><span class="p">)</span>
                    <span class="c1"># Pass the timm_name if specified in config, otherwise model_name</span>
                    <span class="n">timm_model_id</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;timm_name&quot;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_name</span><span class="p">)</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">_load_image_model_timm</span><span class="p">(</span><span class="n">timm_model_id</span><span class="p">)</span>
                <span class="k">except</span> <span class="ne">Exception</span><span class="p">:</span> 
                    <span class="bp">self</span><span class="o">.</span><span class="n">_load_image_model_torchvision</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model_name</span><span class="p">)</span> 
            <span class="k">elif</span> <span class="n">source</span> <span class="o">==</span> <span class="s2">&quot;timm&quot;</span><span class="p">:</span>
                <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">timm</span><span class="p">,</span> <span class="s1">&#39;create_model&#39;</span><span class="p">):</span> <span class="k">raise</span> <span class="ne">ImportError</span><span class="p">(</span><span class="s2">&quot;TIMM not available&quot;</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_load_image_model_timm</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s2">&quot;timm_name&quot;</span><span class="p">])</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Unsupported image model source for </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">model_name</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">source</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">task_type</span> <span class="o">==</span> <span class="s2">&quot;text&quot;</span><span class="p">:</span>
            <span class="c1"># ... (text loading logic as in v0.2.9)</span>
            <span class="k">if</span> <span class="n">source</span> <span class="o">==</span> <span class="s2">&quot;sentence-transformers&quot;</span><span class="p">:</span>
                <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">SentenceTransformer</span><span class="p">,</span> <span class="s1">&#39;encode&#39;</span><span class="p">):</span> 
                     <span class="k">raise</span> <span class="ne">ImportError</span><span class="p">(</span><span class="s2">&quot;Sentence-Transformers dummy class detected or not installed.&quot;</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">SentenceTransformer</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s2">&quot;st_name&quot;</span><span class="p">],</span> <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
            <span class="k">elif</span> <span class="n">source</span> <span class="o">==</span> <span class="s2">&quot;transformers&quot;</span><span class="p">:</span>
                <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">AutoTokenizer</span><span class="p">,</span> <span class="s1">&#39;from_pretrained&#39;</span><span class="p">):</span> 
                    <span class="k">raise</span> <span class="ne">ImportError</span><span class="p">(</span><span class="s2">&quot;Transformers (AutoTokenizer) dummy class detected or not installed.&quot;</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s2">&quot;hf_name&quot;</span><span class="p">])</span>
                <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">AutoModel</span><span class="p">,</span> <span class="s1">&#39;from_pretrained&#39;</span><span class="p">):</span>
                     <span class="k">raise</span> <span class="ne">ImportError</span><span class="p">(</span><span class="s2">&quot;Transformers (AutoModel) dummy class detected or not installed.&quot;</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">AutoModel</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s2">&quot;hf_name&quot;</span><span class="p">])</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Unsupported text model source: </span><span class="si">{</span><span class="n">source</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">task_type</span> <span class="o">==</span> <span class="s2">&quot;video&quot;</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">source</span> <span class="o">==</span> <span class="s2">&quot;torchvision&quot;</span><span class="p">:</span>
                <span class="n">actual_tv_model_name</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;tv_model_name&quot;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_name</span><span class="p">)</span> 

                <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">tv_video_models</span><span class="p">,</span> <span class="n">actual_tv_model_name</span><span class="p">):</span> 
                    <span class="k">raise</span> <span class="ne">ImportError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Video model &#39;</span><span class="si">{</span><span class="n">actual_tv_model_name</span><span class="si">}</span><span class="s2">&#39; not found in torchvision.models.video.&quot;</span><span class="p">)</span>
                <span class="n">model_fn</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">tv_video_models</span><span class="p">,</span> <span class="n">actual_tv_model_name</span><span class="p">)</span>

                <span class="n">weights_enum_name_map</span> <span class="o">=</span> <span class="p">{</span>
                    <span class="s2">&quot;r2plus1d_18&quot;</span><span class="p">:</span> <span class="s2">&quot;R2Plus1D_18_Weights&quot;</span><span class="p">,</span>
                    <span class="s2">&quot;swin_t&quot;</span><span class="p">:</span> <span class="s2">&quot;Swin_T_Weights&quot;</span><span class="p">,</span>
                    <span class="s2">&quot;swin_s&quot;</span><span class="p">:</span> <span class="s2">&quot;Swin_S_Weights&quot;</span><span class="p">,</span>
                    <span class="s2">&quot;swin_b&quot;</span><span class="p">:</span> <span class="s2">&quot;Swin_B_Weights&quot;</span><span class="p">,</span>
                    <span class="c1"># Add other torchvision video model internal names to their Weight enum names here</span>
                <span class="p">}</span>
                <span class="n">weights_enum_name</span> <span class="o">=</span> <span class="n">weights_enum_name_map</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">actual_tv_model_name</span><span class="p">)</span>
                <span class="n">weights_value_name</span> <span class="o">=</span> <span class="s2">&quot;KINETICS400_V1&quot;</span> <span class="c1"># Common, can be overridden by specific model needs</span>

                <span class="k">if</span> <span class="n">weights_enum_name</span><span class="p">:</span>
                    <span class="k">try</span><span class="p">:</span>
                        <span class="n">weights_enum_class</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">tv_video_models</span><span class="p">,</span> <span class="n">weights_enum_name</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
                        <span class="k">if</span> <span class="n">weights_enum_class</span><span class="p">:</span>
                            <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">weights_enum_class</span><span class="p">,</span> <span class="s1">&#39;DEFAULT&#39;</span><span class="p">):</span> 
                                <span class="n">weights_obj</span> <span class="o">=</span> <span class="n">weights_enum_class</span><span class="o">.</span><span class="n">DEFAULT</span>
                            <span class="k">elif</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">weights_enum_class</span><span class="p">,</span> <span class="n">weights_value_name</span><span class="p">):</span>
                                <span class="n">weights_obj</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">weights_enum_class</span><span class="p">,</span> <span class="n">weights_value_name</span><span class="p">)</span>
                            <span class="k">else</span><span class="p">:</span> <span class="c1"># Try first available uppercase if common ones fail</span>
                                <span class="n">available_weights</span> <span class="o">=</span> <span class="p">[</span><span class="n">w</span> <span class="k">for</span> <span class="n">w</span> <span class="ow">in</span> <span class="nb">dir</span><span class="p">(</span><span class="n">weights_enum_class</span><span class="p">)</span> <span class="k">if</span> <span class="n">w</span><span class="o">.</span><span class="n">isupper</span><span class="p">()</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">w</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s1">&#39;_&#39;</span><span class="p">)]</span>
                                <span class="k">if</span> <span class="n">available_weights</span><span class="p">:</span>
                                    <span class="n">weights_obj</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">weights_enum_class</span><span class="p">,</span> <span class="n">available_weights</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
                                    <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;DLFeat: Using first available weight &#39;</span><span class="si">{</span><span class="n">available_weights</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">}</span><span class="s2">&#39; for </span><span class="si">{</span><span class="n">actual_tv_model_name</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
                                <span class="k">else</span><span class="p">:</span> <span class="k">raise</span> <span class="ne">AttributeError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;No suitable weights found in </span><span class="si">{</span><span class="n">weights_enum_name</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
                            
                            <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">model_fn</span><span class="p">(</span><span class="n">weights</span><span class="o">=</span><span class="n">weights_obj</span><span class="p">)</span>
                            <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">weights_obj</span><span class="p">,</span> <span class="s1">&#39;transforms&#39;</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">callable</span><span class="p">(</span><span class="n">weights_obj</span><span class="o">.</span><span class="n">transforms</span><span class="p">):</span>
                                <span class="bp">self</span><span class="o">.</span><span class="n">video_frame_transform</span> <span class="o">=</span> <span class="n">weights_obj</span><span class="o">.</span><span class="n">transforms</span><span class="p">()</span>
                                <span class="c1"># print(f&quot;DLFeat: Using default transforms from weights for {actual_tv_model_name}&quot;) # Debug</span>
                        <span class="k">else</span><span class="p">:</span> <span class="k">raise</span> <span class="ne">AttributeError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">weights_enum_name</span><span class="si">}</span><span class="s2"> enum not found.&quot;</span><span class="p">)</span>
                    <span class="k">except</span> <span class="p">(</span><span class="ne">AttributeError</span><span class="p">,</span> <span class="ne">ValueError</span><span class="p">)</span> <span class="k">as</span> <span class="n">e_new_api</span><span class="p">:</span>
                        <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span>
                            <span class="sa">f</span><span class="s2">&quot;DLFeatExtractor: Failed to use new &#39;weights&#39; API for </span><span class="si">{</span><span class="n">actual_tv_model_name</span><span class="si">}</span><span class="s2"> (Error: </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">e_new_api</span><span class="p">)</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">e_new_api</span><span class="si">}</span><span class="s2">). &quot;</span>
                            <span class="sa">f</span><span class="s2">&quot;Falling back to legacy &#39;pretrained=True&#39; if applicable.&quot;</span>
                        <span class="p">)</span>
                        <span class="c1"># Check if &#39;pretrained&#39; is even a valid kwarg for this model_fn</span>
                        <span class="kn">import</span><span class="w"> </span><span class="nn">inspect</span>
                        <span class="n">sig</span> <span class="o">=</span> <span class="n">inspect</span><span class="o">.</span><span class="n">signature</span><span class="p">(</span><span class="n">model_fn</span><span class="p">)</span>
                        <span class="k">if</span> <span class="s1">&#39;pretrained&#39;</span> <span class="ow">in</span> <span class="n">sig</span><span class="o">.</span><span class="n">parameters</span><span class="p">:</span>
                            <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">model_fn</span><span class="p">(</span><span class="n">pretrained</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
                        <span class="k">else</span><span class="p">:</span>
                            <span class="k">raise</span> <span class="ne">ImportError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;New weights API failed for </span><span class="si">{</span><span class="n">actual_tv_model_name</span><span class="si">}</span><span class="s2"> and legacy &#39;pretrained&#39; not supported or model init failed.&quot;</span><span class="p">)</span>
                <span class="k">else</span><span class="p">:</span> 
                    <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span>
                        <span class="sa">f</span><span class="s2">&quot;DLFeatExtractor: No specific &#39;weights&#39; API logic for </span><span class="si">{</span><span class="n">actual_tv_model_name</span><span class="si">}</span><span class="s2">. Attempting legacy &#39;pretrained=True&#39;.&quot;</span>
                    <span class="p">)</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">model_fn</span><span class="p">(</span><span class="n">pretrained</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span> <span class="c1"># Fallback for unhandled models</span>

                <span class="c1"># Remove classifier head (common patterns)</span>
                <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="s1">&#39;head&#39;</span><span class="p">):</span> 
                    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">head</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">):</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">head</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Identity</span><span class="p">()</span>
                    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">head</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">head</span><span class="p">)</span><span class="o">&gt;</span><span class="mi">0</span> <span class="ow">and</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">head</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">):</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">head</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Identity</span><span class="p">()</span>
                <span class="k">elif</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="s1">&#39;fc&#39;</span><span class="p">):</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">fc</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Identity</span><span class="p">()</span> 
                
                <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>

                <span class="c1"># If transforms weren&#39;t set from weights, set a basic default</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">video_frame_transform</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="n">input_size</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;input_size&quot;</span><span class="p">,</span> <span class="mi">224</span><span class="p">)</span>
                    <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;DLFeat: Using manual basic transforms for </span><span class="si">{</span><span class="n">actual_tv_model_name</span><span class="si">}</span><span class="s2"> as weights.transforms() was not available/used.&quot;</span><span class="p">)</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">video_frame_transform</span> <span class="o">=</span> <span class="n">T</span><span class="o">.</span><span class="n">Compose</span><span class="p">([</span> <span class="c1"># This transform is applied PER FRAME in _preprocess_video_torchvision</span>
                        <span class="n">T</span><span class="o">.</span><span class="n">ConvertImageDtype</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">),</span>
                        <span class="n">T</span><span class="o">.</span><span class="n">Normalize</span><span class="p">(</span><span class="n">mean</span><span class="o">=</span><span class="p">[</span><span class="mf">0.43216</span><span class="p">,</span> <span class="mf">0.394666</span><span class="p">,</span> <span class="mf">0.37645</span><span class="p">],</span> <span class="n">std</span><span class="o">=</span><span class="p">[</span><span class="mf">0.22803</span><span class="p">,</span> <span class="mf">0.22145</span><span class="p">,</span> <span class="mf">0.216989</span><span class="p">]),</span> <span class="c1"># Kinetics mean/std</span>
                        <span class="n">T</span><span class="o">.</span><span class="n">Resize</span><span class="p">([</span><span class="n">input_size</span><span class="p">,</span> <span class="n">input_size</span><span class="p">],</span> <span class="n">antialias</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span> 
                    <span class="p">])</span>
            <span class="k">elif</span> <span class="n">source</span> <span class="o">==</span> <span class="s2">&quot;pytorchvideo&quot;</span><span class="p">:</span>
                <span class="c1"># ... (pytorchvideo loading logic as in v0.2.9, with SlowFast specific create)</span>
                <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">EncodedVideo</span><span class="p">,</span> <span class="s1">&#39;from_path&#39;</span><span class="p">):</span> 
                    <span class="k">raise</span> <span class="ne">ImportError</span><span class="p">(</span><span class="s2">&quot;PyTorchVideo dummy class detected or not installed.&quot;</span><span class="p">)</span>
                
                <span class="n">ptv_hub_model_name</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;ptv_hub_name&quot;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_name</span><span class="p">)</span>
                <span class="k">try</span><span class="p">:</span>
                    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_name</span> <span class="o">==</span> <span class="s2">&quot;slowfast_r50&quot;</span><span class="p">:</span>
                         <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">ptv_models</span><span class="p">,</span> <span class="s1">&#39;slowfast&#39;</span><span class="p">)</span> <span class="ow">or</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="nb">getattr</span><span class="p">(</span><span class="n">ptv_models</span><span class="p">,</span> <span class="s1">&#39;slowfast&#39;</span><span class="p">),</span> <span class="s1">&#39;create_slowfast&#39;</span><span class="p">):</span> 
                             <span class="k">raise</span> <span class="ne">ImportError</span><span class="p">(</span><span class="s2">&quot;PTV slowfast model or create_slowfast method not found.&quot;</span><span class="p">)</span>
                         <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">ptv_models</span><span class="o">.</span><span class="n">slowfast</span><span class="o">.</span><span class="n">create_slowfast</span><span class="p">(</span><span class="n">head_activation</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">model_num_class</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span> <span class="c1"># For features</span>
                         <span class="c1"># For PTV create_* functions, manual weight loading is often needed.</span>
                         <span class="c1"># This part is complex for a generic library. We assume torch.hub handles most cases.</span>
                         <span class="c1"># For slowfast, users might need to load weights manually or use a hub version if PTV provides one under that name.</span>
                         <span class="c1"># The ptv_hub_name for slowfast_r50 in MODEL_CONFIGS might point to a hub-loadable version.</span>
                         <span class="c1"># If ptv_hub_name IS &quot;slowfast_r50&quot;, torch.hub.load will be attempted:</span>
                         <span class="k">if</span> <span class="n">ptv_hub_model_name</span> <span class="o">==</span> <span class="s2">&quot;slowfast_r50&quot;</span><span class="p">:</span> <span class="c1"># Redundant check if this path is taken</span>
                              <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">hub</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">&quot;facebookresearch/pytorchvideo&quot;</span><span class="p">,</span> <span class="n">model</span><span class="o">=</span><span class="s2">&quot;slowfast_r50&quot;</span><span class="p">,</span> <span class="n">pretrained</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">trust_repo</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
                         <span class="k">else</span><span class="p">:</span> <span class="c1"># If create_slowfast was used and needs manual weights</span>
                             <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span><span class="s2">&quot;DLFeat: PTV SlowFast model created; ensure weights are loaded if not handled by create_slowfast.&quot;</span><span class="p">)</span>
                    <span class="k">else</span><span class="p">:</span> <span class="c1"># For MViT etc.</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">hub</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">&quot;facebookresearch/pytorchvideo&quot;</span><span class="p">,</span> <span class="n">model</span><span class="o">=</span><span class="n">ptv_hub_model_name</span><span class="p">,</span> <span class="n">pretrained</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">trust_repo</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span> 
                <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
                    <span class="k">raise</span> <span class="ne">ImportError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Failed to load PyTorchVideo model </span><span class="si">{</span><span class="n">ptv_hub_model_name</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">. &quot;</span><span class="p">)</span>

                <span class="c1"># Classifier removal for PTV models</span>
                <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="s1">&#39;blocks&#39;</span><span class="p">)</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">blocks</span> <span class="ow">and</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">blocks</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="s1">&#39;proj&#39;</span><span class="p">):</span> <span class="c1"># MViT</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">blocks</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">proj</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Identity</span><span class="p">()</span> 
                <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_name</span> <span class="o">==</span> <span class="s2">&quot;slowfast_r50&quot;</span> <span class="ow">and</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="s1">&#39;blocks&#39;</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">blocks</span><span class="p">)</span> <span class="o">==</span> <span class="mi">6</span> <span class="ow">and</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">blocks</span><span class="p">[</span><span class="mi">5</span><span class="p">],</span> <span class="s1">&#39;proj&#39;</span><span class="p">):</span> <span class="c1"># SlowFast specific head path</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">blocks</span><span class="p">[</span><span class="mi">5</span><span class="p">]</span><span class="o">.</span><span class="n">proj</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Identity</span><span class="p">()</span>
                <span class="k">elif</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="s1">&#39;head&#39;</span><span class="p">):</span> <span class="c1"># More general PTV head patterns</span>
                     <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">head</span><span class="p">,</span> <span class="s1">&#39;projection&#39;</span><span class="p">):</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">head</span><span class="o">.</span><span class="n">projection</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Identity</span><span class="p">()</span>
                     <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">head</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">):</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">head</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Identity</span><span class="p">()</span>

                <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">video_transform_params</span> <span class="o">=</span> <span class="p">{</span> 
                    <span class="s2">&quot;side_size&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;input_size&quot;</span><span class="p">,</span> <span class="mi">224</span><span class="p">)</span> <span class="o">+</span> <span class="mi">32</span><span class="p">,</span> 
                    <span class="s2">&quot;crop_size&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;input_size&quot;</span><span class="p">,</span> <span class="mi">224</span><span class="p">),</span>
                    <span class="s2">&quot;num_frames&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;clip_len&quot;</span><span class="p">,</span> <span class="mi">32</span><span class="p">),</span> 
                    <span class="s2">&quot;sampling_rate&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;frame_rate_alpha&quot;</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_name</span><span class="o">==</span><span class="s2">&quot;slowfast_r50&quot;</span> <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;frame_rate&quot;</span><span class="p">,</span> <span class="mi">8</span><span class="p">),</span> 
                    <span class="s2">&quot;video_mean&quot;</span><span class="p">:</span> <span class="p">(</span><span class="mf">0.45</span><span class="p">,</span> <span class="mf">0.45</span><span class="p">,</span> <span class="mf">0.45</span><span class="p">),</span>
                    <span class="s2">&quot;video_std&quot;</span><span class="p">:</span> <span class="p">(</span><span class="mf">0.225</span><span class="p">,</span> <span class="mf">0.225</span><span class="p">,</span> <span class="mf">0.225</span><span class="p">),</span>
                <span class="p">}</span>
            <span class="k">elif</span> <span class="n">source</span> <span class="o">==</span> <span class="s2">&quot;transformers&quot;</span><span class="p">:</span> 
                <span class="c1"># ... (transformers video loading logic for VideoMAE, as in v0.2.9)</span>
                <span class="c1"># For VideoSwin, ProcessorClass would be VideoSwinImageProcessor (dummy if not imported)</span>
                <span class="c1"># ModelClass would be VideoSwinModel (dummy if not imported)</span>
                <span class="c1"># Since VideoSwin moved to torchvision, this path is mainly for VideoMAE now.</span>
                <span class="n">ProcessorClass</span> <span class="o">=</span> <span class="n">VideoMAEFeatureExtractor</span> <span class="c1"># Assuming only VideoMAE uses this path now</span>
                <span class="n">ModelClass</span> <span class="o">=</span> <span class="n">VideoMAEModel</span>
                
                <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">ProcessorClass</span><span class="p">,</span> <span class="s1">&#39;from_pretrained&#39;</span><span class="p">):</span> 
                    <span class="k">raise</span> <span class="ne">ImportError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Transformers (</span><span class="si">{</span><span class="n">ProcessorClass</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2">) dummy class detected or not installed.&quot;</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">processor</span> <span class="o">=</span> <span class="n">ProcessorClass</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s2">&quot;hf_name&quot;</span><span class="p">])</span>
                
                <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">ModelClass</span><span class="p">,</span> <span class="s1">&#39;from_pretrained&#39;</span><span class="p">):</span>
                    <span class="k">raise</span> <span class="ne">ImportError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Transformers (</span><span class="si">{</span><span class="n">ModelClass</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2">) dummy class detected or not installed.&quot;</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">ModelClass</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s2">&quot;hf_name&quot;</span><span class="p">])</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
            <span class="k">elif</span> <span class="n">source</span> <span class="o">==</span> <span class="s2">&quot;timm&quot;</span><span class="p">:</span> <span class="c1"># For TSM</span>
                 <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">timm</span><span class="p">,</span> <span class="s1">&#39;create_model&#39;</span><span class="p">):</span> <span class="k">raise</span> <span class="ne">ImportError</span><span class="p">(</span><span class="s2">&quot;TIMM not available&quot;</span><span class="p">)</span>
                 <span class="bp">self</span><span class="o">.</span><span class="n">_load_image_model_timm</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s2">&quot;timm_name&quot;</span><span class="p">])</span> 
            <span class="k">else</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Unsupported video model source: </span><span class="si">{</span><span class="n">source</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">task_type</span> <span class="o">==</span> <span class="s2">&quot;audio&quot;</span><span class="p">:</span>
            <span class="c1"># ... (audio loading logic as in v0.2.9)</span>
            <span class="n">ProcessorCheckClass</span> <span class="o">=</span> <span class="n">ASTFeatureExtractor</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_name</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s2">&quot;ast&quot;</span><span class="p">)</span> <span class="k">else</span> <span class="n">Wav2Vec2FeatureExtractor</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">ProcessorCheckClass</span><span class="p">,</span> <span class="s1">&#39;from_pretrained&#39;</span><span class="p">):</span> 
                <span class="k">raise</span> <span class="ne">ImportError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Transformers (</span><span class="si">{</span><span class="n">ProcessorCheckClass</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2">) dummy class detected or not installed.&quot;</span><span class="p">)</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">TA</span><span class="p">,</span> <span class="s1">&#39;Resample&#39;</span><span class="p">):</span>  
                <span class="k">raise</span> <span class="ne">ImportError</span><span class="p">(</span><span class="s2">&quot;Torchaudio (transforms.Resample) dummy class detected or not installed.&quot;</span><span class="p">)</span>

            <span class="n">hf_name</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s2">&quot;hf_name&quot;</span><span class="p">]</span>
            <span class="n">ProcessorClassToUse</span> <span class="o">=</span> <span class="n">ASTFeatureExtractor</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_name</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s2">&quot;ast&quot;</span><span class="p">)</span> <span class="k">else</span> <span class="n">Wav2Vec2FeatureExtractor</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">processor</span> <span class="o">=</span> <span class="n">ProcessorClassToUse</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">hf_name</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">AutoModel</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">hf_name</span><span class="p">)</span> 
            <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">target_sr</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s2">&quot;sampling_rate&quot;</span><span class="p">]</span> 

        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">task_type</span> <span class="o">==</span> <span class="s2">&quot;multimodal_image_text&quot;</span><span class="p">:</span>
            <span class="c1"># ... (multimodal_image_text loading logic as in v0.2.9)</span>
            <span class="n">ProcessorCheckClass</span> <span class="o">=</span> <span class="n">BlipProcessor</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_name</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s2">&quot;blip&quot;</span><span class="p">)</span> <span class="k">else</span> <span class="n">CLIPProcessor</span>
            <span class="n">ModelCheckClass</span> <span class="o">=</span> <span class="n">BlipModel</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_name</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s2">&quot;blip&quot;</span><span class="p">)</span> <span class="k">else</span> <span class="n">CLIPModel</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">ProcessorCheckClass</span><span class="p">,</span> <span class="s1">&#39;from_pretrained&#39;</span><span class="p">)</span> <span class="ow">or</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">ModelCheckClass</span><span class="p">,</span> <span class="s1">&#39;from_pretrained&#39;</span><span class="p">):</span>
                <span class="k">raise</span> <span class="ne">ImportError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Transformers (</span><span class="si">{</span><span class="n">ProcessorCheckClass</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2"> or </span><span class="si">{</span><span class="n">ModelCheckClass</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2">) dummy class detected or not installed.&quot;</span><span class="p">)</span>
            
            <span class="n">hf_name</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s2">&quot;hf_name&quot;</span><span class="p">]</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">processor</span> <span class="o">=</span> <span class="n">ProcessorCheckClass</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">hf_name</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">ModelCheckClass</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">hf_name</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>

        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">task_type</span> <span class="o">==</span> <span class="s2">&quot;multimodal_video_text&quot;</span><span class="p">:</span>
            <span class="c1"># ... (multimodal_video_text loading logic as in v0.2.9)</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">XCLIPProcessor</span><span class="p">,</span> <span class="s1">&#39;from_pretrained&#39;</span><span class="p">)</span> <span class="ow">or</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">XCLIPModel</span><span class="p">,</span> <span class="s1">&#39;from_pretrained&#39;</span><span class="p">):</span> 
                <span class="k">raise</span> <span class="ne">ImportError</span><span class="p">(</span><span class="s2">&quot;Transformers (XCLIP components) dummy class detected or not installed.&quot;</span><span class="p">)</span>
            <span class="n">hf_name</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s2">&quot;hf_name&quot;</span><span class="p">]</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">processor</span> <span class="o">=</span> <span class="n">XCLIPProcessor</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">hf_name</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">XCLIPModel</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">hf_name</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
            
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Unsupported task type: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">task_type</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        
    <span class="c1"># --- Preprocessing methods ---</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">_preprocess_image</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">image_input</span><span class="p">):</span>
        <span class="c1"># ... (same as v0.2.9)</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">image_input</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">image_input</span><span class="p">):</span> <span class="k">raise</span> <span class="ne">FileNotFoundError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Image file: </span><span class="si">{</span><span class="n">image_input</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="n">img</span> <span class="o">=</span> <span class="n">Image</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="n">image_input</span><span class="p">)</span><span class="o">.</span><span class="n">convert</span><span class="p">(</span><span class="s2">&quot;RGB&quot;</span><span class="p">)</span>
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">image_input</span><span class="p">,</span> <span class="n">Image</span><span class="o">.</span><span class="n">Image</span><span class="p">):</span> <span class="n">img</span> <span class="o">=</span> <span class="n">image_input</span><span class="o">.</span><span class="n">convert</span><span class="p">(</span><span class="s2">&quot;RGB&quot;</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span> <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s2">&quot;Image input must be a file path or PIL Image.&quot;</span><span class="p">)</span>
        
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_name</span> <span class="o">==</span> <span class="s2">&quot;dinov2_base&quot;</span><span class="p">:</span> 
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">processor</span><span class="p">(</span><span class="n">images</span><span class="o">=</span><span class="n">img</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;pt&quot;</span><span class="p">)</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">image_transform</span><span class="p">:</span> 
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">image_transform</span><span class="p">(</span><span class="n">img</span><span class="p">)</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span> 
        <span class="k">else</span><span class="p">:</span> 
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;No image transform or processor available for </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">model_name</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_preprocess_text_transformers</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">text_input</span><span class="p">):</span>
        <span class="c1"># ... (same as v0.2.9)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">(</span><span class="n">text_input</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">truncation</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;pt&quot;</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_preprocess_video_torchvision</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">video_path</span><span class="p">):</span>
        <span class="c1"># Updated to prefer transforms from weights and handle (T,C,H,W) input</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">video_path</span><span class="p">):</span> <span class="k">raise</span> <span class="ne">FileNotFoundError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Video file: </span><span class="si">{</span><span class="n">video_path</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="n">frames</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">info</span> <span class="o">=</span> <span class="n">torchvision</span><span class="o">.</span><span class="n">io</span><span class="o">.</span><span class="n">read_video</span><span class="p">(</span><span class="n">video_path</span><span class="p">,</span> <span class="n">pts_unit</span><span class="o">=</span><span class="s1">&#39;sec&#39;</span><span class="p">,</span> <span class="n">output_format</span><span class="o">=</span><span class="s2">&quot;T_C_H_W&quot;</span><span class="p">)</span> <span class="c1"># T, C, H, W uint8</span>
        <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span> <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Failed to read </span><span class="si">{</span><span class="n">video_path</span><span class="si">}</span><span class="s2"> using torchvision.io: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">.&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">frames</span><span class="o">.</span><span class="n">numel</span><span class="p">()</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span> <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;No frames from </span><span class="si">{</span><span class="n">video_path</span><span class="si">}</span><span class="s2">.&quot;</span><span class="p">)</span>

        <span class="n">total_frames</span> <span class="o">=</span> <span class="n">frames</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">clip_len</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;clip_len&quot;</span><span class="p">,</span> <span class="mi">32</span><span class="p">)</span> 
        
        <span class="k">if</span> <span class="n">total_frames</span> <span class="o">&lt;</span> <span class="n">clip_len</span><span class="p">:</span> <span class="c1"># Pad if too short</span>
            <span class="n">padding_count</span> <span class="o">=</span> <span class="n">clip_len</span> <span class="o">-</span> <span class="n">total_frames</span>
            <span class="n">padding_frames</span> <span class="o">=</span> <span class="n">frames</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">:]</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="n">padding_count</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span> <span class="c1"># Repeat last frame</span>
            <span class="n">sampled_frames</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">((</span><span class="n">frames</span><span class="p">,</span> <span class="n">padding_frames</span><span class="p">),</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span> <span class="c1"># Uniformly sample clip_len frames</span>
            <span class="n">indices</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">total_frames</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="n">steps</span><span class="o">=</span><span class="n">clip_len</span><span class="p">)</span><span class="o">.</span><span class="n">long</span><span class="p">()</span>
            <span class="n">sampled_frames</span> <span class="o">=</span> <span class="n">frames</span><span class="p">[</span><span class="n">indices</span><span class="p">]</span> <span class="c1"># (clip_len, C, H, W) tensor</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">video_frame_transform</span><span class="p">:</span>
            <span class="c1"># This transform (e.g., from weights.DEFAULT.transforms()) should handle the whole (T,C,H,W) uint8 clip</span>
            <span class="c1"># and output a (C,T,H,W) float32 normalized tensor.</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="n">processed_clip</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">video_frame_transform</span><span class="p">(</span><span class="n">sampled_frames</span><span class="p">)</span> <span class="c1"># Input T,C,H,W ; Output C,T,H,W expected</span>
                <span class="c1"># Some transforms might already output C,T,H,W directly. Others might need permute.</span>
                <span class="c1"># The standard video transforms from torchvision.models.video.&lt;Model&gt;_Weights.DEFAULT.transforms()</span>
                <span class="c1"># usually output C,T,H,W</span>
                <span class="k">if</span> <span class="n">processed_clip</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">!=</span> <span class="mi">3</span> <span class="ow">or</span> <span class="n">processed_clip</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">!=</span> <span class="n">clip_len</span><span class="p">:</span> <span class="c1"># Basic sanity check, C should be 3</span>
                    <span class="c1"># Try to infer if it&#39;s T,C,H,W and needs permute</span>
                    <span class="k">if</span> <span class="n">processed_clip</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">==</span> <span class="mi">3</span> <span class="ow">and</span> <span class="n">processed_clip</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="n">clip_len</span><span class="p">:</span>
                        <span class="n">processed_clip</span> <span class="o">=</span> <span class="n">processed_clip</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">)</span> <span class="c1"># T,C,H,W -&gt; C,T,H,W</span>
                    <span class="c1"># else: pass through, hope for the best or rely on model to handle it</span>
            <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e_transform</span><span class="p">:</span>
                 <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Error applying self.video_frame_transform for </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">model_name</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">e_transform</span><span class="si">}</span><span class="s2">. &quot;</span>
                                    <span class="sa">f</span><span class="s2">&quot;Input shape was </span><span class="si">{</span><span class="n">sampled_frames</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">, transform type: </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">video_frame_transform</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span> <span class="c1"># Fallback: manual per-frame (should be rare if weights.transforms() is used)</span>
            <span class="n">input_size</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;input_size&quot;</span><span class="p">,</span> <span class="mi">224</span><span class="p">)</span>
            <span class="n">manual_per_frame_transform</span> <span class="o">=</span> <span class="n">T</span><span class="o">.</span><span class="n">Compose</span><span class="p">([</span>
                 <span class="n">T</span><span class="o">.</span><span class="n">ConvertImageDtype</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">),</span>
                 <span class="n">T</span><span class="o">.</span><span class="n">Normalize</span><span class="p">(</span><span class="n">mean</span><span class="o">=</span><span class="p">[</span><span class="mf">0.43216</span><span class="p">,</span> <span class="mf">0.394666</span><span class="p">,</span> <span class="mf">0.37645</span><span class="p">],</span> <span class="n">std</span><span class="o">=</span><span class="p">[</span><span class="mf">0.22803</span><span class="p">,</span> <span class="mf">0.22145</span><span class="p">,</span> <span class="mf">0.216989</span><span class="p">]),</span>
                 <span class="n">T</span><span class="o">.</span><span class="n">Resize</span><span class="p">([</span><span class="n">input_size</span><span class="p">,</span> <span class="n">input_size</span><span class="p">],</span> <span class="n">antialias</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
            <span class="p">])</span>
            <span class="n">processed_frames_list</span> <span class="o">=</span> <span class="p">[</span><span class="n">manual_per_frame_transform</span><span class="p">(</span><span class="n">frame</span><span class="p">)</span> <span class="k">for</span> <span class="n">frame</span> <span class="ow">in</span> <span class="n">sampled_frames</span><span class="p">]</span> <span class="c1"># frame is (C,H,W)</span>
            <span class="n">processed_clip_temp</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">processed_frames_list</span><span class="p">)</span> <span class="c1"># (T,C,H,W)</span>
            <span class="n">processed_clip</span> <span class="o">=</span> <span class="n">processed_clip_temp</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">)</span> <span class="c1"># (C,T,H,W)</span>
            
        <span class="k">return</span> <span class="n">processed_clip</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span> <span class="c1"># B, C, T, H, W</span>


    <span class="k">def</span><span class="w"> </span><span class="nf">_preprocess_video_pytorchvideo</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">video_path</span><span class="p">):</span>
        <span class="c1"># ... (same as v0.2.9)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">video_path</span><span class="p">):</span> <span class="k">raise</span> <span class="ne">FileNotFoundError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Video file: </span><span class="si">{</span><span class="n">video_path</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">EncodedVideo</span><span class="p">,</span> <span class="s1">&#39;from_path&#39;</span><span class="p">)</span> <span class="ow">or</span> \
           <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">ptv_transforms</span><span class="p">,</span> <span class="s1">&#39;Normalize&#39;</span><span class="p">)</span> <span class="ow">or</span> \
           <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">ptv_data_transforms</span><span class="p">,</span> <span class="s1">&#39;UniformTemporalSubsample&#39;</span><span class="p">):</span> 
             <span class="k">raise</span> <span class="ne">ImportError</span><span class="p">(</span><span class="s2">&quot;PyTorchVideo components appear to be dummy classes or not imported correctly.&quot;</span><span class="p">)</span>

        <span class="n">params</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">video_transform_params</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_name</span> <span class="o">==</span> <span class="s2">&quot;slowfast_r50&quot;</span><span class="p">:</span>
            <span class="c1"># Simplified single-pathway transform for DLFeat&#39;s SlowFast.</span>
            <span class="c1"># True SlowFast requires a list of 2 tensors (slow and fast pathways).</span>
            <span class="c1"># PyTorchVideo&#39;s hub model for &quot;slowfast_r50&quot; might be adapted to handle single input.</span>
            <span class="n">transform</span> <span class="o">=</span> <span class="n">T</span><span class="o">.</span><span class="n">Compose</span><span class="p">([</span>
                <span class="n">ptv_data_transforms</span><span class="o">.</span><span class="n">UniformTemporalSubsample</span><span class="p">(</span><span class="n">params</span><span class="p">[</span><span class="s2">&quot;num_frames&quot;</span><span class="p">]),</span> <span class="c1"># Fast pathway sampling</span>
                <span class="n">T</span><span class="o">.</span><span class="n">Lambda</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span> <span class="o">/</span> <span class="mf">255.0</span><span class="p">),</span> 
                <span class="n">ptv_transforms</span><span class="o">.</span><span class="n">Normalize</span><span class="p">(</span><span class="n">params</span><span class="p">[</span><span class="s2">&quot;video_mean&quot;</span><span class="p">],</span> <span class="n">params</span><span class="p">[</span><span class="s2">&quot;video_std&quot;</span><span class="p">]),</span>
                <span class="n">ptv_transforms</span><span class="o">.</span><span class="n">ShortSideScale</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="n">params</span><span class="p">[</span><span class="s2">&quot;side_size&quot;</span><span class="p">]),</span>
                <span class="n">ptv_transforms</span><span class="o">.</span><span class="n">CenterCrop</span><span class="p">(</span><span class="n">params</span><span class="p">[</span><span class="s2">&quot;crop_size&quot;</span><span class="p">]),</span>
                <span class="c1"># ptv_transforms.PackPathway() # Omitted for simplicity, model might handle single tensor input</span>
            <span class="p">])</span>
            <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span><span class="s2">&quot;DLFeat&#39;s SlowFast preprocessing is simplified (single pathway simulated). &quot;</span>
                          <span class="s2">&quot;For optimal features or if model expects list input, consult PyTorchVideo SlowFast examples.&quot;</span><span class="p">,</span> <span class="ne">UserWarning</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span> 
            <span class="n">transform</span> <span class="o">=</span> <span class="n">T</span><span class="o">.</span><span class="n">Compose</span><span class="p">([</span>
                <span class="n">ptv_data_transforms</span><span class="o">.</span><span class="n">UniformTemporalSubsample</span><span class="p">(</span><span class="n">params</span><span class="p">[</span><span class="s2">&quot;num_frames&quot;</span><span class="p">]),</span>
                <span class="n">T</span><span class="o">.</span><span class="n">Lambda</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span> <span class="o">/</span> <span class="mf">255.0</span><span class="p">),</span> 
                <span class="n">ptv_transforms</span><span class="o">.</span><span class="n">Normalize</span><span class="p">(</span><span class="n">params</span><span class="p">[</span><span class="s2">&quot;video_mean&quot;</span><span class="p">],</span> <span class="n">params</span><span class="p">[</span><span class="s2">&quot;video_std&quot;</span><span class="p">]),</span>
                <span class="n">ptv_transforms</span><span class="o">.</span><span class="n">ShortSideScale</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="n">params</span><span class="p">[</span><span class="s2">&quot;side_size&quot;</span><span class="p">]),</span>
                <span class="n">ptv_transforms</span><span class="o">.</span><span class="n">CenterCrop</span><span class="p">(</span><span class="n">params</span><span class="p">[</span><span class="s2">&quot;crop_size&quot;</span><span class="p">]),</span>
            <span class="p">])</span>
        
        <span class="n">nominal_fps</span> <span class="o">=</span> <span class="mi">30</span> 
        <span class="n">duration_to_sample_sec</span> <span class="o">=</span> <span class="p">(</span><span class="n">params</span><span class="p">[</span><span class="s2">&quot;num_frames&quot;</span><span class="p">]</span> <span class="o">*</span> <span class="n">params</span><span class="p">[</span><span class="s2">&quot;sampling_rate&quot;</span><span class="p">])</span> <span class="o">/</span> <span class="n">nominal_fps</span>

        <span class="n">video</span> <span class="o">=</span> <span class="n">EncodedVideo</span><span class="o">.</span><span class="n">from_path</span><span class="p">(</span><span class="n">video_path</span><span class="p">)</span> 
        <span class="n">video_duration_sec</span> <span class="o">=</span> <span class="n">video</span><span class="o">.</span><span class="n">duration</span>
        
        <span class="n">start_sec</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="p">(</span><span class="n">video_duration_sec</span> <span class="o">-</span> <span class="n">duration_to_sample_sec</span><span class="p">)</span> <span class="o">/</span> <span class="mi">2</span><span class="p">)</span>
        <span class="n">end_sec</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="n">video_duration_sec</span><span class="p">,</span> <span class="n">start_sec</span> <span class="o">+</span> <span class="n">duration_to_sample_sec</span><span class="p">)</span>
        
        <span class="k">if</span> <span class="n">start_sec</span> <span class="o">&gt;=</span> <span class="n">end_sec</span> <span class="ow">and</span> <span class="n">video_duration_sec</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">start_sec</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">end_sec</span> <span class="o">=</span> <span class="n">video_duration_sec</span>
        
        <span class="k">try</span><span class="p">:</span>
            <span class="n">video_data</span> <span class="o">=</span> <span class="n">video</span><span class="o">.</span><span class="n">get_clip</span><span class="p">(</span><span class="n">start_sec</span><span class="o">=</span><span class="n">start_sec</span><span class="p">,</span> <span class="n">end_sec</span><span class="o">=</span><span class="n">end_sec</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">video_data</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="n">video_data</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;video&#39;</span><span class="p">)</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="n">video_data</span><span class="p">[</span><span class="s1">&#39;video&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">numel</span><span class="p">()</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Empty clip returned by get_clip&quot;</span><span class="p">)</span>
        <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
            <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;PTV get_clip failed for </span><span class="si">{</span><span class="n">video_path</span><span class="si">}</span><span class="s2"> (start=</span><span class="si">{</span><span class="n">start_sec</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">, end=</span><span class="si">{</span><span class="n">end_sec</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">, duration=</span><span class="si">{</span><span class="n">video_duration_sec</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">): </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">. Trying full video.&quot;</span><span class="p">)</span>
            <span class="n">video_data</span> <span class="o">=</span> <span class="n">video</span><span class="o">.</span><span class="n">get_clip</span><span class="p">(</span><span class="n">start_sec</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">end_sec</span><span class="o">=</span><span class="n">video_duration_sec</span><span class="p">)</span> 

        <span class="k">if</span> <span class="n">video_data</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="n">video_data</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;video&#39;</span><span class="p">)</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="n">video_data</span><span class="p">[</span><span class="s1">&#39;video&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">numel</span><span class="p">()</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Failed to decode any clip from </span><span class="si">{</span><span class="n">video_path</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        
        <span class="n">transformed_clip_dict</span> <span class="o">=</span> <span class="n">transform</span><span class="p">(</span><span class="n">video_data</span><span class="p">)</span>
        
        <span class="c1"># If model (like SlowFast from hub) expects a list of tensors, PackPathway should have handled it.</span>
        <span class="c1"># If not, transformed_clip_dict[&#39;video&#39;] is a tensor.</span>
        <span class="c1"># Forcing to list for models that might expect it (e.g. some PTV SlowFast implementations)</span>
        <span class="c1"># This is a heuristic. The hub model for slowfast_r50 might be robust to single tensor.</span>
        <span class="c1"># if self.model_name == &quot;slowfast_r50&quot; and not isinstance(transformed_clip_dict[&#39;video&#39;], list):</span>
        <span class="c1">#    return [transformed_clip_dict[&#39;video&#39;].unsqueeze(0)] # Wrap in list and add batch</span>
            
        <span class="k">return</span> <span class="n">transformed_clip_dict</span><span class="p">[</span><span class="s1">&#39;video&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span> 


    <span class="k">def</span><span class="w"> </span><span class="nf">_preprocess_video_transformers</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">video_path</span><span class="p">):</span> 
        <span class="c1"># ... (same as v0.2.9)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">video_path</span><span class="p">):</span> <span class="k">raise</span> <span class="ne">FileNotFoundError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Video file: </span><span class="si">{</span><span class="n">video_path</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="n">frames_tensor</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">torchvision</span><span class="o">.</span><span class="n">io</span><span class="o">.</span><span class="n">read_video</span><span class="p">(</span><span class="n">video_path</span><span class="p">,</span> <span class="n">pts_unit</span><span class="o">=</span><span class="s1">&#39;sec&#39;</span><span class="p">,</span> <span class="n">output_format</span><span class="o">=</span><span class="s2">&quot;T_H_W_C&quot;</span><span class="p">)</span>
        <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span> <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Failed to read </span><span class="si">{</span><span class="n">video_path</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">.&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">frames_tensor</span><span class="o">.</span><span class="n">numel</span><span class="p">()</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span> <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;No frames from </span><span class="si">{</span><span class="n">video_path</span><span class="si">}</span><span class="s2">.&quot;</span><span class="p">)</span>

        <span class="n">total_frames</span> <span class="o">=</span> <span class="n">frames_tensor</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">num_sample_frames</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;num_frames&quot;</span><span class="p">,</span> <span class="mi">16</span><span class="p">)</span> <span class="c1"># Default, specific models might override in MODEL_CONFIGS</span>
        
        <span class="k">if</span> <span class="n">total_frames</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span> <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Video </span><span class="si">{</span><span class="n">video_path</span><span class="si">}</span><span class="s2"> has 0 frames.&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">num_sample_frames</span> <span class="o">&gt;</span> <span class="n">total_frames</span> <span class="p">:</span> <span class="n">num_sample_frames</span> <span class="o">=</span> <span class="n">total_frames</span>
        
        <span class="n">indices</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">total_frames</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="n">num_sample_frames</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">int</span><span class="p">)</span>
        
        <span class="n">video_frames_list_np</span> <span class="o">=</span> <span class="p">[</span><span class="n">frame</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span> <span class="k">for</span> <span class="n">frame</span> <span class="ow">in</span> <span class="n">frames_tensor</span><span class="p">[</span><span class="n">indices</span><span class="p">]]</span> 
        
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_name</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s2">&quot;xclip&quot;</span><span class="p">):</span>
            <span class="k">return</span> <span class="p">[</span><span class="n">Image</span><span class="o">.</span><span class="n">fromarray</span><span class="p">(</span><span class="n">frame</span><span class="p">)</span> <span class="k">for</span> <span class="n">frame</span> <span class="ow">in</span> <span class="n">video_frames_list_np</span><span class="p">]</span> 
        <span class="k">else</span><span class="p">:</span> <span class="c1"># VideoMAE, (formerly VideoSwin)</span>
            <span class="c1"># self.processor is VideoMAEFeatureExtractor or VideoSwinImageProcessor (if it were still HF)</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">processor</span><span class="p">(</span><span class="n">images</span><span class="o">=</span><span class="n">video_frames_list_np</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;pt&quot;</span><span class="p">)</span> 
    
    <span class="k">def</span><span class="w"> </span><span class="nf">_preprocess_video_timm</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">video_path</span><span class="p">):</span> <span class="c1"># For TSM</span>
        <span class="c1"># ... (same as v0.3.0)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">video_path</span><span class="p">):</span> <span class="k">raise</span> <span class="ne">FileNotFoundError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Video file: </span><span class="si">{</span><span class="n">video_path</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="n">frames_tensor</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">torchvision</span><span class="o">.</span><span class="n">io</span><span class="o">.</span><span class="n">read_video</span><span class="p">(</span><span class="n">video_path</span><span class="p">,</span> <span class="n">pts_unit</span><span class="o">=</span><span class="s1">&#39;sec&#39;</span><span class="p">,</span> <span class="n">output_format</span><span class="o">=</span><span class="s2">&quot;T_H_W_C&quot;</span><span class="p">)</span>
        <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span> <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Failed to read </span><span class="si">{</span><span class="n">video_path</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">.&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">frames_tensor</span><span class="o">.</span><span class="n">numel</span><span class="p">()</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span> <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;No frames from </span><span class="si">{</span><span class="n">video_path</span><span class="si">}</span><span class="s2">.&quot;</span><span class="p">)</span>

        <span class="n">total_frames</span> <span class="o">=</span> <span class="n">frames_tensor</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">num_sample_frames</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;num_frames&quot;</span><span class="p">,</span> <span class="mi">8</span><span class="p">)</span> 
        <span class="k">if</span> <span class="n">num_sample_frames</span> <span class="o">&gt;</span> <span class="n">total_frames</span><span class="p">:</span> <span class="n">num_sample_frames</span> <span class="o">=</span> <span class="n">total_frames</span>
        
        <span class="n">indices</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">total_frames</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="n">num_sample_frames</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">int</span><span class="p">)</span>
        
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">image_transform</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s2">&quot;Image transform (from TIMM base model) not initialized for TSM video model.&quot;</span><span class="p">)</span>

        <span class="n">processed_frames</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="n">indices</span><span class="p">:</span>
            <span class="n">frame_pil</span> <span class="o">=</span> <span class="n">Image</span><span class="o">.</span><span class="n">fromarray</span><span class="p">(</span><span class="n">frames_tensor</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span><span class="o">.</span><span class="n">numpy</span><span class="p">())</span>
            <span class="n">processed_frame</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">image_transform</span><span class="p">(</span><span class="n">frame_pil</span><span class="p">)</span> <span class="c1"># C, H, W</span>
            <span class="n">processed_frames</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">processed_frame</span><span class="p">)</span>
        
        <span class="n">stacked_frames</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">processed_frames</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="c1"># C, T, H, W</span>
        <span class="k">return</span> <span class="n">stacked_frames</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span> <span class="c1"># B, C, T, H, W</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_preprocess_audio</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">audio_input</span><span class="p">):</span>
        <span class="c1"># ... (same as v0.2.9)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">TA</span><span class="p">,</span> <span class="s1">&#39;Resample&#39;</span><span class="p">):</span> 
             <span class="k">raise</span> <span class="ne">ImportError</span><span class="p">(</span><span class="s2">&quot;Torchaudio (transforms.Resample) dummy class detected or not installed.&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">audio_input</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">audio_input</span><span class="p">):</span> <span class="k">raise</span> <span class="ne">FileNotFoundError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Audio file: </span><span class="si">{</span><span class="n">audio_input</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="k">try</span><span class="p">:</span> <span class="n">waveform</span><span class="p">,</span> <span class="n">sr</span> <span class="o">=</span> <span class="n">torchaudio</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">audio_input</span><span class="p">)</span> 
            <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span> <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Failed to load </span><span class="si">{</span><span class="n">audio_input</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span> <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s2">&quot;Audio input must be a file path.&quot;</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">sr</span> <span class="o">!=</span> <span class="bp">self</span><span class="o">.</span><span class="n">target_sr</span><span class="p">:</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">audio_resampler</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">audio_resampler</span><span class="o">.</span><span class="n">orig_freq</span> <span class="o">!=</span> <span class="n">sr</span><span class="p">:</span>
                <span class="n">ResamplerClass</span> <span class="o">=</span> <span class="n">TA</span><span class="o">.</span><span class="n">Resample</span> 
                <span class="bp">self</span><span class="o">.</span><span class="n">audio_resampler</span> <span class="o">=</span> <span class="n">ResamplerClass</span><span class="p">(</span><span class="n">orig_freq</span><span class="o">=</span><span class="n">sr</span><span class="p">,</span> <span class="n">new_freq</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">target_sr</span><span class="p">,</span>
                                                   <span class="n">dtype</span><span class="o">=</span><span class="n">waveform</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">waveform</span><span class="o">.</span><span class="n">device</span><span class="p">)</span> 
            <span class="n">waveform</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">audio_resampler</span><span class="p">(</span><span class="n">waveform</span><span class="p">)</span>
        
        <span class="k">if</span> <span class="n">waveform</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span> <span class="n">waveform</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">waveform</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span> 
        
        <span class="n">processed_input_data</span> <span class="o">=</span> <span class="n">waveform</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span> 
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_name</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s2">&quot;ast&quot;</span><span class="p">):</span> 
             <span class="n">processed_input_data</span> <span class="o">=</span> <span class="n">waveform</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span> 

        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">processor</span><span class="p">(</span><span class="n">processed_input_data</span><span class="p">,</span> <span class="n">sampling_rate</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">target_sr</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;pt&quot;</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<div class="viewcode-block" id="DLFeatExtractor.fit">
<a class="viewcode-back" href="../index.html#DLFeat.DLFeatExtractor.fit">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="c1"># ... (same as v0.2.9)</span>
        <span class="k">return</span> <span class="bp">self</span></div>


<div class="viewcode-block" id="DLFeatExtractor.transform">
<a class="viewcode-back" href="../index.html#DLFeat.DLFeatExtractor.transform">[docs]</a>
    <span class="nd">@torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">()</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">transform</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="c1"># ... (same as v0.3.0, with TSM call to _preprocess_video_timm)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s2">&quot;Input X for transform must be a list of items.&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">X</span><span class="p">:</span> 
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">task_type</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;multimodal_image_text&quot;</span><span class="p">,</span> <span class="s2">&quot;multimodal_video_text&quot;</span><span class="p">]:</span>
                <span class="n">feat_keys</span> <span class="o">=</span> <span class="n">MODEL_CONFIGS</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">model_name</span><span class="p">][</span><span class="s2">&quot;dim&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">keys</span><span class="p">()</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">MODEL_CONFIGS</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">model_name</span><span class="p">][</span><span class="s2">&quot;dim&quot;</span><span class="p">],</span> <span class="nb">dict</span><span class="p">)</span> <span class="k">else</span> \
                            <span class="p">([</span><span class="s2">&quot;image_features&quot;</span><span class="p">,</span> <span class="s2">&quot;text_features&quot;</span><span class="p">]</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">task_type</span> <span class="o">==</span> <span class="s2">&quot;multimodal_image_text&quot;</span> <span class="k">else</span> <span class="p">[</span><span class="s2">&quot;video_features&quot;</span><span class="p">,</span> <span class="s2">&quot;text_features&quot;</span><span class="p">])</span>
                <span class="k">return</span> <span class="p">{</span><span class="n">key</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([])</span> <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">feat_keys</span><span class="p">}</span>
            <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([])</span>

        <span class="n">all_features_batches</span> <span class="o">=</span> <span class="p">[]</span> 

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">task_type</span> <span class="o">==</span> <span class="s2">&quot;image&quot;</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">X</span><span class="p">),</span> <span class="n">batch_size</span><span class="p">):</span>
                <span class="n">batch_items</span> <span class="o">=</span> <span class="n">X</span><span class="p">[</span><span class="n">i</span><span class="p">:</span><span class="n">i</span><span class="o">+</span><span class="n">batch_size</span><span class="p">]</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_name</span> <span class="o">==</span> <span class="s2">&quot;dinov2_base&quot;</span><span class="p">:</span>
                    <span class="n">pil_images</span> <span class="o">=</span> <span class="p">[]</span>
                    <span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">batch_items</span><span class="p">:</span>
                        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">item</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span> <span class="n">pil_images</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">Image</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="n">item</span><span class="p">)</span><span class="o">.</span><span class="n">convert</span><span class="p">(</span><span class="s2">&quot;RGB&quot;</span><span class="p">))</span>
                        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">item</span><span class="p">,</span> <span class="n">Image</span><span class="o">.</span><span class="n">Image</span><span class="p">):</span> <span class="n">pil_images</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">item</span><span class="o">.</span><span class="n">convert</span><span class="p">(</span><span class="s2">&quot;RGB&quot;</span><span class="p">))</span>
                        <span class="k">else</span><span class="p">:</span> <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s2">&quot;DINOv2 expects image path or PIL Image.&quot;</span><span class="p">)</span>
                    <span class="n">inputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">processor</span><span class="p">(</span><span class="n">images</span><span class="o">=</span><span class="n">pil_images</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;pt&quot;</span><span class="p">)</span> 
                    <span class="n">inputs</span> <span class="o">=</span> <span class="p">{</span><span class="n">k</span><span class="p">:</span> <span class="n">v</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">inputs</span><span class="o">.</span><span class="n">items</span><span class="p">()}</span> 
                    <span class="n">outputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">(</span><span class="o">**</span><span class="n">inputs</span><span class="p">)</span>
                    <span class="n">features</span> <span class="o">=</span> <span class="n">outputs</span><span class="o">.</span><span class="n">pooler_output</span> 
                <span class="k">else</span><span class="p">:</span> 
                    <span class="n">processed_batch_tensors</span> <span class="o">=</span> <span class="p">[]</span>
                    <span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">batch_items</span><span class="p">:</span>
                        <span class="n">processed_item_output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_preprocess_image</span><span class="p">(</span><span class="n">item</span><span class="p">)</span> 
                        <span class="n">processed_batch_tensors</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">processed_item_output</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="mi">0</span><span class="p">))</span>
                    
                    <span class="k">if</span> <span class="ow">not</span> <span class="n">processed_batch_tensors</span><span class="p">:</span> <span class="k">continue</span>
                    <span class="n">final_batch_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">processed_batch_tensors</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
                    <span class="n">features</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">(</span><span class="n">final_batch_tensor</span><span class="p">)</span>
                <span class="n">all_features_batches</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">features</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">())</span>

        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">task_type</span> <span class="o">==</span> <span class="s2">&quot;text&quot;</span><span class="p">:</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s2">&quot;source&quot;</span><span class="p">]</span> <span class="o">==</span> <span class="s2">&quot;sentence-transformers&quot;</span><span class="p">:</span>
                <span class="n">features</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">convert_to_numpy</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
                <span class="n">all_features_batches</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">features</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span> 
                <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">X</span><span class="p">),</span> <span class="n">batch_size</span><span class="p">):</span>
                    <span class="n">batch_texts</span> <span class="o">=</span> <span class="n">X</span><span class="p">[</span><span class="n">i</span><span class="p">:</span><span class="n">i</span><span class="o">+</span><span class="n">batch_size</span><span class="p">]</span>
                    <span class="n">inputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_preprocess_text_transformers</span><span class="p">(</span><span class="n">batch_texts</span><span class="p">)</span>
                    <span class="n">inputs</span> <span class="o">=</span> <span class="p">{</span><span class="n">k</span><span class="p">:</span> <span class="n">v</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">inputs</span><span class="o">.</span><span class="n">items</span><span class="p">()}</span>
                    <span class="n">outputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">(</span><span class="o">**</span><span class="n">inputs</span><span class="p">)</span>
                    <span class="n">features</span> <span class="o">=</span> <span class="n">outputs</span><span class="o">.</span><span class="n">last_hidden_state</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">,</span> <span class="p">:]</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span> 
                    <span class="n">all_features_batches</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">features</span><span class="p">)</span>
        
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">task_type</span> <span class="o">==</span> <span class="s2">&quot;video&quot;</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">X</span><span class="p">),</span> <span class="n">batch_size</span><span class="p">):</span>
                <span class="n">batch_video_paths</span> <span class="o">=</span> <span class="n">X</span><span class="p">[</span><span class="n">i</span><span class="p">:</span><span class="n">i</span><span class="o">+</span><span class="n">batch_size</span><span class="p">]</span>
                <span class="n">processed_clips_tensors</span> <span class="o">=</span> <span class="p">[]</span>
                <span class="k">for</span> <span class="n">video_path</span> <span class="ow">in</span> <span class="n">batch_video_paths</span><span class="p">:</span>
                    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s2">&quot;source&quot;</span><span class="p">]</span> <span class="o">==</span> <span class="s2">&quot;torchvision&quot;</span><span class="p">:</span>
                        <span class="n">clip_tensor</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_preprocess_video_torchvision</span><span class="p">(</span><span class="n">video_path</span><span class="p">)</span> 
                    <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s2">&quot;source&quot;</span><span class="p">]</span> <span class="o">==</span> <span class="s2">&quot;pytorchvideo&quot;</span><span class="p">:</span>
                        <span class="n">clip_tensor</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_preprocess_video_pytorchvideo</span><span class="p">(</span><span class="n">video_path</span><span class="p">)</span> 
                    <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s2">&quot;source&quot;</span><span class="p">]</span> <span class="o">==</span> <span class="s2">&quot;transformers&quot;</span><span class="p">:</span> 
                        <span class="n">video_inputs_dict</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_preprocess_video_transformers</span><span class="p">(</span><span class="n">video_path</span><span class="p">)</span> 
                        <span class="n">clip_tensor</span> <span class="o">=</span> <span class="n">video_inputs_dict</span><span class="p">[</span><span class="s1">&#39;pixel_values&#39;</span><span class="p">]</span> 
                    <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s2">&quot;source&quot;</span><span class="p">]</span> <span class="o">==</span> <span class="s2">&quot;timm&quot;</span><span class="p">:</span> 
                        <span class="n">clip_tensor</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_preprocess_video_timm</span><span class="p">(</span><span class="n">video_path</span><span class="p">)</span>
                    <span class="k">else</span><span class="p">:</span>
                        <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Video preprocessing not implemented for </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s1">&#39;source&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
                    <span class="n">processed_clips_tensors</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">clip_tensor</span><span class="p">)</span>
                
                <span class="k">if</span> <span class="ow">not</span> <span class="n">processed_clips_tensors</span><span class="p">:</span> <span class="k">continue</span>
                <span class="n">batch_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span><span class="n">processed_clips_tensors</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
                
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s2">&quot;source&quot;</span><span class="p">]</span> <span class="o">==</span> <span class="s2">&quot;transformers&quot;</span><span class="p">:</span> 
                    <span class="n">outputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">(</span><span class="n">pixel_values</span><span class="o">=</span><span class="n">batch_tensor</span><span class="p">)</span> 
                    <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="s1">&#39;pooler_output&#39;</span><span class="p">)</span> <span class="ow">and</span> <span class="n">outputs</span><span class="o">.</span><span class="n">pooler_output</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                        <span class="n">features</span> <span class="o">=</span> <span class="n">outputs</span><span class="o">.</span><span class="n">pooler_output</span>
                    <span class="k">else</span><span class="p">:</span>
                        <span class="n">features</span> <span class="o">=</span> <span class="n">outputs</span><span class="o">.</span><span class="n">last_hidden_state</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> 
                <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s2">&quot;source&quot;</span><span class="p">]</span> <span class="o">==</span> <span class="s2">&quot;pytorchvideo&quot;</span><span class="p">:</span>
                    <span class="c1"># PTV SlowFast might expect a list of tensors if PackPathway was used in transform</span>
                    <span class="c1"># If self.model(batch_tensor) fails for slowfast, it might be expecting list input.</span>
                    <span class="c1"># The hub &quot;slowfast_r50&quot; model usually handles single tensor input by replicating for pathways.</span>
                    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_name</span> <span class="o">==</span> <span class="s2">&quot;slowfast_r50&quot;</span> <span class="ow">and</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">batch_tensor</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
                        <span class="c1"># Some PTV slowfast models might expect inputs as [slow_path_tensor, fast_path_tensor]</span>
                        <span class="c1"># The hub model is often more flexible. Forcing list for robustness if needed.</span>
                        <span class="c1"># features = self.model([batch_tensor, batch_tensor]) # Example, if model takes list</span>
                        <span class="n">features</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">(</span><span class="n">batch_tensor</span><span class="p">)</span> <span class="c1"># Assuming hub model handles it</span>
                    <span class="k">else</span><span class="p">:</span>
                        <span class="n">features</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">(</span><span class="n">batch_tensor</span><span class="p">)</span> 

                    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">features</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span> <span class="n">features</span> <span class="o">=</span> <span class="n">features</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="c1"># Often, PTV models return list of outputs</span>
                    <span class="k">if</span> <span class="n">features</span><span class="o">.</span><span class="n">ndim</span> <span class="o">&gt;</span> <span class="mi">2</span> <span class="ow">and</span> <span class="n">features</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="n">batch_tensor</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]:</span> <span class="c1"># Ensure batch dim matches</span>
                         <span class="c1"># Global average pool over remaining spatial/temporal dimensions if any</span>
                         <span class="n">features</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">features</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="n">features</span><span class="o">.</span><span class="n">ndim</span><span class="p">)))</span>
                    <span class="k">elif</span> <span class="n">features</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">1</span> <span class="ow">and</span> <span class="n">batch_tensor</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mi">1</span> <span class="p">:</span> <span class="c1"># (B*D) case, needs reshape</span>
                         <span class="n">expected_dim</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_feature_dimension</span><span class="p">()</span>
                         <span class="k">if</span> <span class="n">features</span><span class="o">.</span><span class="n">numel</span><span class="p">()</span> <span class="o">==</span> <span class="n">batch_tensor</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="n">expected_dim</span> <span class="p">:</span>
                              <span class="n">features</span> <span class="o">=</span> <span class="n">features</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">batch_tensor</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">expected_dim</span><span class="p">)</span>

                <span class="k">else</span><span class="p">:</span> <span class="c1"># torchvision, timm (TSM)</span>
                    <span class="n">features</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">(</span><span class="n">batch_tensor</span><span class="p">)</span> 
                <span class="n">all_features_batches</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">features</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">())</span>

        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">task_type</span> <span class="o">==</span> <span class="s2">&quot;audio&quot;</span><span class="p">:</span>
            <span class="c1"># ... (same as v0.2.9)</span>
            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">X</span><span class="p">),</span> <span class="n">batch_size</span><span class="p">):</span>
                <span class="n">batch_audio_paths</span> <span class="o">=</span> <span class="n">X</span><span class="p">[</span><span class="n">i</span><span class="p">:</span><span class="n">i</span><span class="o">+</span><span class="n">batch_size</span><span class="p">]</span>
                <span class="n">batch_item_features_list</span> <span class="o">=</span> <span class="p">[]</span>
                <span class="k">for</span> <span class="n">audio_path</span> <span class="ow">in</span> <span class="n">batch_audio_paths</span><span class="p">:</span>
                    <span class="n">inputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_preprocess_audio</span><span class="p">(</span><span class="n">audio_path</span><span class="p">)</span> 
                    <span class="n">inputs</span> <span class="o">=</span> <span class="p">{</span><span class="n">k</span><span class="p">:</span> <span class="n">v</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">inputs</span><span class="o">.</span><span class="n">items</span><span class="p">()}</span>
                    <span class="n">outputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">(</span><span class="o">**</span><span class="n">inputs</span><span class="p">)</span>
                    <span class="n">item_features</span> <span class="o">=</span> <span class="n">outputs</span><span class="o">.</span><span class="n">last_hidden_state</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> 
                    <span class="n">batch_item_features_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">item_features</span><span class="p">)</span>
                <span class="k">if</span> <span class="n">batch_item_features_list</span><span class="p">:</span>
                    <span class="n">stacked_features</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span><span class="n">batch_item_features_list</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
                    <span class="n">all_features_batches</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">stacked_features</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">())</span>

        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">task_type</span> <span class="o">==</span> <span class="s2">&quot;multimodal_image_text&quot;</span><span class="p">:</span>
            <span class="c1"># ... (same as v0.2.9)</span>
            <span class="n">img_feats_list</span><span class="p">,</span> <span class="n">text_feats_list</span> <span class="o">=</span> <span class="p">[],</span> <span class="p">[]</span>
            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">X</span><span class="p">),</span> <span class="n">batch_size</span><span class="p">):</span>
                <span class="n">batch_tuples</span> <span class="o">=</span> <span class="n">X</span><span class="p">[</span><span class="n">i</span><span class="p">:</span><span class="n">i</span><span class="o">+</span><span class="n">batch_size</span><span class="p">]</span>
                <span class="n">pil_images</span> <span class="o">=</span> <span class="p">[</span><span class="n">Image</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="n">item</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span><span class="o">.</span><span class="n">convert</span><span class="p">(</span><span class="s2">&quot;RGB&quot;</span><span class="p">)</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">item</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="nb">str</span><span class="p">)</span> <span class="k">else</span> <span class="n">item</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">convert</span><span class="p">(</span><span class="s2">&quot;RGB&quot;</span><span class="p">)</span> <span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">batch_tuples</span><span class="p">]</span>
                <span class="n">str_texts</span> <span class="o">=</span> <span class="p">[</span><span class="n">item</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">batch_tuples</span><span class="p">]</span>

                <span class="n">inputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">processor</span><span class="p">(</span><span class="n">text</span><span class="o">=</span><span class="n">str_texts</span><span class="p">,</span> <span class="n">images</span><span class="o">=</span><span class="n">pil_images</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;pt&quot;</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">truncation</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
                <span class="n">inputs</span> <span class="o">=</span> <span class="p">{</span><span class="n">k</span><span class="p">:</span> <span class="n">v</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">inputs</span><span class="o">.</span><span class="n">items</span><span class="p">()}</span>

                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_name</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s2">&quot;clip&quot;</span><span class="p">):</span>
                    <span class="n">outputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">(</span><span class="o">**</span><span class="n">inputs</span><span class="p">)</span>
                    <span class="n">img_feats_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">outputs</span><span class="o">.</span><span class="n">image_embeds</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">())</span>
                    <span class="n">text_feats_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">outputs</span><span class="o">.</span><span class="n">text_embeds</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">())</span>
                <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_name</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s2">&quot;blip&quot;</span><span class="p">):</span> 
                    <span class="n">image_features</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">get_image_features</span><span class="p">(</span><span class="n">pixel_values</span><span class="o">=</span><span class="n">inputs</span><span class="p">[</span><span class="s1">&#39;pixel_values&#39;</span><span class="p">])</span>
                    <span class="n">text_features</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">get_text_features</span><span class="p">(</span><span class="n">input_ids</span><span class="o">=</span><span class="n">inputs</span><span class="p">[</span><span class="s1">&#39;input_ids&#39;</span><span class="p">],</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">inputs</span><span class="p">[</span><span class="s1">&#39;attention_mask&#39;</span><span class="p">])</span>
                    <span class="n">img_feats_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">image_features</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">())</span>
                    <span class="n">text_feats_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">text_features</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">())</span>
                <span class="k">else</span><span class="p">:</span> <span class="k">raise</span> <span class="ne">NotImplementedError</span>

            <span class="n">final_output_dict</span> <span class="o">=</span> <span class="p">{}</span>
            <span class="k">if</span> <span class="n">img_feats_list</span><span class="p">:</span> <span class="n">final_output_dict</span><span class="p">[</span><span class="s2">&quot;image_features&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">(</span><span class="n">img_feats_list</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">text_feats_list</span><span class="p">:</span> <span class="n">final_output_dict</span><span class="p">[</span><span class="s2">&quot;text_features&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">(</span><span class="n">text_feats_list</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">final_output_dict</span>

        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">task_type</span> <span class="o">==</span> <span class="s2">&quot;multimodal_video_text&quot;</span><span class="p">:</span> 
            <span class="c1"># ... (same as v0.2.9)</span>
            <span class="n">vid_feats_list</span><span class="p">,</span> <span class="n">txt_feats_list</span> <span class="o">=</span> <span class="p">[],</span> <span class="p">[]</span>
            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">X</span><span class="p">),</span> <span class="n">batch_size</span><span class="p">):</span> 
                <span class="n">batch_tuples</span> <span class="o">=</span> <span class="n">X</span><span class="p">[</span><span class="n">i</span><span class="p">:</span><span class="n">i</span><span class="o">+</span><span class="n">batch_size</span><span class="p">]</span>
                
                <span class="n">batch_video_pil_frames</span> <span class="o">=</span> <span class="p">[]</span> 
                <span class="k">for</span> <span class="n">video_path</span><span class="p">,</span> <span class="n">_</span> <span class="ow">in</span> <span class="n">batch_tuples</span><span class="p">:</span>
                    <span class="n">single_video_pil_frames</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_preprocess_video_transformers</span><span class="p">(</span><span class="n">video_path</span><span class="p">)</span>
                    <span class="n">batch_video_pil_frames</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">single_video_pil_frames</span><span class="p">)</span>

                <span class="n">text_queries</span> <span class="o">=</span> <span class="p">[</span><span class="n">item</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">batch_tuples</span><span class="p">]</span>
                
                <span class="n">inputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">processor</span><span class="p">(</span><span class="n">text</span><span class="o">=</span><span class="n">text_queries</span><span class="p">,</span> <span class="n">videos</span><span class="o">=</span><span class="n">batch_video_pil_frames</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;pt&quot;</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
                <span class="n">inputs</span> <span class="o">=</span> <span class="p">{</span><span class="n">k</span><span class="p">:</span> <span class="n">v</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">inputs</span><span class="o">.</span><span class="n">items</span><span class="p">()}</span>
                
                <span class="n">outputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">(</span><span class="o">**</span><span class="n">inputs</span><span class="p">)</span>
                <span class="n">vid_feats_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">outputs</span><span class="o">.</span><span class="n">video_embeds</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">())</span>
                <span class="n">txt_feats_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">outputs</span><span class="o">.</span><span class="n">text_embeds</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">())</span>

            <span class="n">final_output_dict</span> <span class="o">=</span> <span class="p">{}</span>
            <span class="k">if</span> <span class="n">vid_feats_list</span><span class="p">:</span> <span class="n">final_output_dict</span><span class="p">[</span><span class="s2">&quot;video_features&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">(</span><span class="n">vid_feats_list</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">txt_feats_list</span><span class="p">:</span> <span class="n">final_output_dict</span><span class="p">[</span><span class="s2">&quot;text_features&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">(</span><span class="n">txt_feats_list</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">final_output_dict</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Transform not implemented for task type: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">task_type</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="n">all_features_batches</span><span class="p">:</span> 
            <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([])</span>
            
        <span class="n">final_features_np</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">(</span><span class="n">all_features_batches</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">final_features_np</span></div>
</div>


<span class="c1"># --- Self-Test Suite ---</span>
<span class="c1"># ... (run_self_tests, _create_dummy_image, _create_dummy_audio, _create_dummy_video same as v0.2.9) ...</span>
<span class="k">def</span><span class="w"> </span><span class="nf">_create_dummy_image</span><span class="p">(</span><span class="n">path</span><span class="o">=</span><span class="s2">&quot;dummy_image_dlfeat.png&quot;</span><span class="p">):</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="n">img</span> <span class="o">=</span> <span class="n">Image</span><span class="o">.</span><span class="n">new</span><span class="p">(</span><span class="s1">&#39;RGB&#39;</span><span class="p">,</span> <span class="p">(</span><span class="mi">224</span><span class="p">,</span> <span class="mi">224</span><span class="p">),</span> <span class="n">color</span> <span class="o">=</span> <span class="s1">&#39;red&#39;</span><span class="p">)</span>
        <span class="n">d</span> <span class="o">=</span> <span class="n">ImageDraw</span><span class="o">.</span><span class="n">Draw</span><span class="p">(</span><span class="n">img</span><span class="p">)</span>
        <span class="n">d</span><span class="o">.</span><span class="n">text</span><span class="p">((</span><span class="mi">10</span><span class="p">,</span><span class="mi">10</span><span class="p">),</span> <span class="s2">&quot;Hello DLFeat&quot;</span><span class="p">,</span> <span class="n">fill</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">))</span>
        <span class="n">img</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">path</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">path</span>
    <span class="k">except</span> <span class="ne">ImportError</span><span class="p">:</span>
        <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span><span class="s2">&quot;Pillow with ImageDraw not available to create dummy image for tests.&quot;</span><span class="p">)</span>
        <span class="k">return</span> <span class="kc">None</span>
    <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
        <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Could not create dummy image: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="k">return</span> <span class="kc">None</span>

<span class="k">def</span><span class="w"> </span><span class="nf">_create_dummy_audio</span><span class="p">(</span><span class="n">path</span><span class="o">=</span><span class="s2">&quot;dummy_audio_dlfeat.wav&quot;</span><span class="p">):</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">scipy_wav</span><span class="p">,</span> <span class="s1">&#39;write&#39;</span><span class="p">)</span> <span class="ow">or</span> <span class="n">scipy_wav</span><span class="o">.</span><span class="vm">__name__</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s1">&#39;dummy_&#39;</span><span class="p">):</span> 
             <span class="k">raise</span> <span class="ne">ImportError</span><span class="p">(</span><span class="s2">&quot;Scipy.io.wavfile not available or is a dummy.&quot;</span><span class="p">)</span>
        <span class="n">sample_rate</span> <span class="o">=</span> <span class="mi">16000</span><span class="p">;</span> <span class="n">duration</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span> <span class="n">frequency</span> <span class="o">=</span> <span class="mi">440</span>
        <span class="n">t</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">duration</span><span class="p">,</span> <span class="nb">int</span><span class="p">(</span><span class="n">sample_rate</span> <span class="o">*</span> <span class="n">duration</span><span class="p">),</span> <span class="n">endpoint</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="n">data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">pi</span> <span class="o">*</span> <span class="n">frequency</span> <span class="o">*</span> <span class="n">t</span><span class="p">)</span> <span class="o">*</span> <span class="mf">0.5</span>
        <span class="n">data_int16</span> <span class="o">=</span> <span class="p">(</span><span class="n">data</span> <span class="o">*</span> <span class="mi">32767</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">int16</span><span class="p">)</span>
        <span class="n">scipy_wav</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">path</span><span class="p">,</span> <span class="n">sample_rate</span><span class="p">,</span> <span class="n">data_int16</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">path</span>
    <span class="k">except</span> <span class="ne">ImportError</span><span class="p">:</span> 
        <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span><span class="s2">&quot;Scipy.io.wavfile not available to create dummy audio for tests.&quot;</span><span class="p">)</span>
        <span class="k">return</span> <span class="kc">None</span>
    <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
        <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Could not create dummy audio: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="k">return</span> <span class="kc">None</span>

<span class="k">def</span><span class="w"> </span><span class="nf">_create_dummy_video</span><span class="p">(</span><span class="n">path</span><span class="o">=</span><span class="s2">&quot;dummy_video_dlfeat.mp4&quot;</span><span class="p">):</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">path</span><span class="p">,</span> <span class="s1">&#39;wb&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
            <span class="n">f</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;This is not a real video file, but a placeholder for DLFeat tests.&quot;</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">path</span>
    <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
        <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Could not create placeholder dummy video file: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="k">return</span> <span class="kc">None</span>

<div class="viewcode-block" id="run_self_tests">
<a class="viewcode-back" href="../index.html#DLFeat.run_self_tests">[docs]</a>
<span class="k">def</span><span class="w"> </span><span class="nf">run_self_tests</span><span class="p">(</span><span class="n">models_to_test</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="s1">&#39;cpu&#39;</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;=&quot;</span><span class="o">*</span><span class="mi">70</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot; DLFeat Self-Test Suite&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;=&quot;</span><span class="o">*</span><span class="mi">70</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">models_to_test</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">models_to_test</span> <span class="o">=</span> <span class="n">DEFAULT_MODELS_TO_TEST</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Running tests for a default set of models: </span><span class="si">{</span><span class="n">models_to_test</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">models_to_test</span><span class="p">,</span> <span class="nb">str</span><span class="p">)</span> <span class="ow">and</span> <span class="n">models_to_test</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span> <span class="o">==</span> <span class="s1">&#39;all&#39;</span><span class="p">:</span>
        <span class="n">models_to_test</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">MODEL_CONFIGS</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Running tests for ALL available models in MODEL_CONFIGS.&quot;</span><span class="p">)</span>
    <span class="k">elif</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">models_to_test</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Warning: &#39;models_to_test&#39; should be a list of model names, &#39;all&#39;, or None. Got </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">models_to_test</span><span class="p">)</span><span class="si">}</span><span class="s2">. Running default set.&quot;</span><span class="p">)</span>
        <span class="n">models_to_test</span> <span class="o">=</span> <span class="n">DEFAULT_MODELS_TO_TEST</span>
    <span class="k">else</span><span class="p">:</span> 
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Running tests for specified models: </span><span class="si">{</span><span class="n">models_to_test</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>


    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">--- Creating dummy files for tests ---&quot;</span><span class="p">)</span>
    <span class="n">dummy_image_path</span> <span class="o">=</span> <span class="n">_create_dummy_image</span><span class="p">()</span>
    <span class="k">if</span> <span class="n">dummy_image_path</span> <span class="ow">and</span> <span class="n">verbose</span><span class="p">:</span> <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Dummy image created: </span><span class="si">{</span><span class="n">dummy_image_path</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="n">dummy_audio_path</span> <span class="o">=</span> <span class="n">_create_dummy_audio</span><span class="p">()</span>
    <span class="k">if</span> <span class="n">dummy_audio_path</span> <span class="ow">and</span> <span class="n">verbose</span><span class="p">:</span> <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Dummy audio created: </span><span class="si">{</span><span class="n">dummy_audio_path</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="n">dummy_video_path</span> <span class="o">=</span> <span class="n">_create_dummy_video</span><span class="p">()</span> 
    <span class="k">if</span> <span class="n">dummy_video_path</span> <span class="ow">and</span> <span class="n">verbose</span><span class="p">:</span> <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Dummy video placeholder created: </span><span class="si">{</span><span class="n">dummy_video_path</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    
    <span class="n">test_results_list</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">text_sample</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;This is a test sentence for DLFeat.&quot;</span><span class="p">,</span> <span class="s2">&quot;Another sentence.&quot;</span><span class="p">]</span>

    <span class="k">for</span> <span class="n">model_name</span> <span class="ow">in</span> <span class="n">models_to_test</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">model_name</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">MODEL_CONFIGS</span><span class="p">:</span>
            <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Model </span><span class="si">{</span><span class="n">model_name</span><span class="si">}</span><span class="s2"> specified for testing not found in MODEL_CONFIGS. Skipping.&quot;</span><span class="p">)</span>
            <span class="n">test_results_list</span><span class="o">.</span><span class="n">append</span><span class="p">({</span>
                <span class="s2">&quot;model_name&quot;</span><span class="p">:</span> <span class="n">model_name</span><span class="p">,</span> <span class="s2">&quot;task&quot;</span><span class="p">:</span> <span class="s2">&quot;N/A&quot;</span><span class="p">,</span> <span class="s2">&quot;source&quot;</span><span class="p">:</span> <span class="s2">&quot;N/A&quot;</span><span class="p">,</span>
                <span class="s2">&quot;availability&quot;</span><span class="p">:</span> <span class="s2">&quot;✗&quot;</span><span class="p">,</span> <span class="s2">&quot;test_status&quot;</span><span class="p">:</span> <span class="s2">&quot;SKIPPED&quot;</span><span class="p">,</span> <span class="s2">&quot;notes&quot;</span><span class="p">:</span> <span class="s2">&quot;Not in MODEL_CONFIGS&quot;</span>
            <span class="p">})</span>
            <span class="k">continue</span>

        <span class="n">config</span> <span class="o">=</span> <span class="n">MODEL_CONFIGS</span><span class="p">[</span><span class="n">model_name</span><span class="p">]</span>
        <span class="n">task</span> <span class="o">=</span> <span class="n">config</span><span class="p">[</span><span class="s2">&quot;task&quot;</span><span class="p">]</span>
        <span class="n">source</span> <span class="o">=</span> <span class="n">config</span><span class="p">[</span><span class="s2">&quot;source&quot;</span><span class="p">]</span>
        
        <span class="n">current_result</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s2">&quot;model_name&quot;</span><span class="p">:</span> <span class="n">model_name</span><span class="p">,</span> <span class="s2">&quot;task&quot;</span><span class="p">:</span> <span class="n">task</span><span class="p">,</span> <span class="s2">&quot;source&quot;</span><span class="p">:</span> <span class="n">source</span><span class="p">,</span>
            <span class="s2">&quot;availability&quot;</span><span class="p">:</span> <span class="s2">&quot;✗&quot;</span><span class="p">,</span> <span class="s2">&quot;test_status&quot;</span><span class="p">:</span> <span class="s2">&quot;SKIPPED&quot;</span><span class="p">,</span> <span class="s2">&quot;notes&quot;</span><span class="p">:</span> <span class="s2">&quot;&quot;</span>
        <span class="p">}</span>
        <span class="n">notes_collector</span> <span class="o">=</span> <span class="p">[]</span>

        <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span> <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">--- Testing: </span><span class="si">{</span><span class="n">model_name</span><span class="si">}</span><span class="s2"> (Task: </span><span class="si">{</span><span class="n">task</span><span class="si">}</span><span class="s2">, Source: </span><span class="si">{</span><span class="n">source</span><span class="si">}</span><span class="s2">) ---&quot;</span><span class="p">)</span>
        
        <span class="n">extractor</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span> <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;[</span><span class="si">{</span><span class="n">model_name</span><span class="si">}</span><span class="s2">] Initializing DLFeatExtractor...&quot;</span><span class="p">)</span>
            <span class="n">extractor</span> <span class="o">=</span> <span class="n">DLFeatExtractor</span><span class="p">(</span><span class="n">model_name</span><span class="o">=</span><span class="n">model_name</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
            <span class="n">current_result</span><span class="p">[</span><span class="s2">&quot;availability&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;✓&quot;</span>
            <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span> <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;[</span><span class="si">{</span><span class="n">model_name</span><span class="si">}</span><span class="s2">] Initialized successfully.&quot;</span><span class="p">)</span>

            <span class="n">dummy_input_data</span> <span class="o">=</span> <span class="kc">None</span>
            <span class="n">expected_batch_size</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="n">is_video_task_with_placeholder</span> <span class="o">=</span> <span class="kc">False</span>

            <span class="k">if</span> <span class="n">task</span> <span class="o">==</span> <span class="s2">&quot;image&quot;</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">dummy_image_path</span> <span class="ow">and</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">dummy_image_path</span><span class="p">):</span> 
                    <span class="n">dummy_input_data</span> <span class="o">=</span> <span class="p">[</span><span class="n">dummy_image_path</span><span class="p">,</span> <span class="n">dummy_image_path</span><span class="p">]</span> 
                    <span class="n">expected_batch_size</span> <span class="o">=</span> <span class="mi">2</span>
                <span class="k">else</span><span class="p">:</span> <span class="n">notes_collector</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s2">&quot;No dummy image.&quot;</span><span class="p">)</span>
            <span class="k">elif</span> <span class="n">task</span> <span class="o">==</span> <span class="s2">&quot;text&quot;</span><span class="p">:</span>
                <span class="n">dummy_input_data</span> <span class="o">=</span> <span class="n">text_sample</span>
                <span class="n">expected_batch_size</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">text_sample</span><span class="p">)</span>
            <span class="k">elif</span> <span class="n">task</span> <span class="o">==</span> <span class="s2">&quot;audio&quot;</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">dummy_audio_path</span> <span class="ow">and</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">dummy_audio_path</span><span class="p">):</span>
                    <span class="n">dummy_input_data</span> <span class="o">=</span> <span class="p">[</span><span class="n">dummy_audio_path</span><span class="p">,</span> <span class="n">dummy_audio_path</span><span class="p">]</span>
                    <span class="n">expected_batch_size</span> <span class="o">=</span> <span class="mi">2</span>
                <span class="k">else</span><span class="p">:</span> <span class="n">notes_collector</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s2">&quot;No dummy audio.&quot;</span><span class="p">)</span>
            <span class="k">elif</span> <span class="n">task</span> <span class="o">==</span> <span class="s2">&quot;video&quot;</span><span class="p">:</span>
                <span class="n">is_video_task_with_placeholder</span> <span class="o">=</span> <span class="kc">True</span> 
                <span class="k">if</span> <span class="n">dummy_video_path</span> <span class="ow">and</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">dummy_video_path</span><span class="p">):</span> 
                    <span class="n">dummy_input_data</span> <span class="o">=</span> <span class="p">[</span><span class="n">dummy_video_path</span><span class="p">,</span> <span class="n">dummy_video_path</span><span class="p">]</span> 
                    <span class="n">expected_batch_size</span> <span class="o">=</span> <span class="mi">2</span> 
                    <span class="c1"># notes_collector.append(&quot;Video transform uses placeholder.&quot;) # Redundant due to special handling</span>
                <span class="k">else</span><span class="p">:</span> <span class="n">notes_collector</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s2">&quot;No dummy video placeholder.&quot;</span><span class="p">)</span>
            <span class="k">elif</span> <span class="n">task</span> <span class="o">==</span> <span class="s2">&quot;multimodal_image_text&quot;</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">dummy_image_path</span> <span class="ow">and</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">dummy_image_path</span><span class="p">):</span>
                    <span class="n">dummy_input_data</span> <span class="o">=</span> <span class="p">[(</span><span class="n">dummy_image_path</span><span class="p">,</span> <span class="n">text_sample</span><span class="p">[</span><span class="mi">0</span><span class="p">]),</span> <span class="p">(</span><span class="n">dummy_image_path</span><span class="p">,</span> <span class="n">text_sample</span><span class="p">[</span><span class="mi">1</span><span class="p">])]</span>
                    <span class="n">expected_batch_size</span> <span class="o">=</span> <span class="mi">2</span>
                <span class="k">else</span><span class="p">:</span> <span class="n">notes_collector</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s2">&quot;No dummy image for multimodal.&quot;</span><span class="p">)</span>
            <span class="k">elif</span> <span class="n">task</span> <span class="o">==</span> <span class="s2">&quot;multimodal_video_text&quot;</span><span class="p">:</span>
                <span class="n">is_video_task_with_placeholder</span> <span class="o">=</span> <span class="kc">True</span> 
                <span class="k">if</span> <span class="n">dummy_video_path</span> <span class="ow">and</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">dummy_video_path</span><span class="p">):</span>
                    <span class="n">dummy_input_data</span> <span class="o">=</span> <span class="p">[(</span><span class="n">dummy_video_path</span><span class="p">,</span> <span class="n">text_sample</span><span class="p">[</span><span class="mi">0</span><span class="p">]),</span> <span class="p">(</span><span class="n">dummy_video_path</span><span class="p">,</span> <span class="n">text_sample</span><span class="p">[</span><span class="mi">1</span><span class="p">])]</span>
                    <span class="n">expected_batch_size</span> <span class="o">=</span> <span class="mi">2</span>
                    <span class="c1"># notes_collector.append(&quot;Multimodal video uses placeholder.&quot;)</span>
                <span class="k">else</span><span class="p">:</span> <span class="n">notes_collector</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s2">&quot;No dummy video placeholder for multimodal.&quot;</span><span class="p">)</span>
            
            <span class="k">if</span> <span class="n">is_video_task_with_placeholder</span> <span class="ow">and</span> <span class="n">current_result</span><span class="p">[</span><span class="s2">&quot;availability&quot;</span><span class="p">]</span> <span class="o">==</span> <span class="s2">&quot;✓&quot;</span><span class="p">:</span>
                <span class="n">current_result</span><span class="p">[</span><span class="s2">&quot;test_status&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;SKIPPED (Transform)&quot;</span>
                <span class="n">notes_collector</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s2">&quot;Transform with placeholder video skipped. Test with real video.&quot;</span><span class="p">)</span>
                <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span> <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;[</span><span class="si">{</span><span class="n">model_name</span><span class="si">}</span><span class="s2">] Transform test SKIPPED due to placeholder video data.&quot;</span><span class="p">)</span>
            <span class="k">elif</span> <span class="n">dummy_input_data</span><span class="p">:</span> 
                <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span> <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;[</span><span class="si">{</span><span class="n">model_name</span><span class="si">}</span><span class="s2">] Attempting feature extraction with batch size </span><span class="si">{</span><span class="n">expected_batch_size</span><span class="si">}</span><span class="s2">...&quot;</span><span class="p">)</span>
                <span class="n">features</span> <span class="o">=</span> <span class="n">extractor</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">dummy_input_data</span><span class="p">)</span>
                
                <span class="k">if</span> <span class="n">task</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s2">&quot;multimodal&quot;</span><span class="p">):</span>
                    <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">features</span><span class="p">,</span> <span class="nb">dict</span><span class="p">):</span>
                        <span class="k">raise</span> <span class="ne">AssertionError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Multimodal features not a dict (got </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">features</span><span class="p">)</span><span class="si">}</span><span class="s2">)&quot;</span><span class="p">)</span>
                    
                    <span class="n">expected_keys_present</span> <span class="o">=</span> <span class="kc">True</span>
                    <span class="k">if</span> <span class="n">task</span> <span class="o">==</span> <span class="s2">&quot;multimodal_image_text&quot;</span> <span class="ow">and</span> <span class="ow">not</span> <span class="p">(</span><span class="s2">&quot;image_features&quot;</span> <span class="ow">in</span> <span class="n">features</span> <span class="ow">and</span> <span class="s2">&quot;text_features&quot;</span> <span class="ow">in</span> <span class="n">features</span><span class="p">):</span>
                        <span class="n">expected_keys_present</span> <span class="o">=</span> <span class="kc">False</span>
                    <span class="k">elif</span> <span class="n">task</span> <span class="o">==</span> <span class="s2">&quot;multimodal_video_text&quot;</span> <span class="ow">and</span> <span class="ow">not</span> <span class="p">(</span><span class="s2">&quot;video_features&quot;</span> <span class="ow">in</span> <span class="n">features</span> <span class="ow">and</span> <span class="s2">&quot;text_features&quot;</span> <span class="ow">in</span> <span class="n">features</span><span class="p">):</span>
                        <span class="n">expected_keys_present</span> <span class="o">=</span> <span class="kc">False</span>
                    <span class="k">if</span> <span class="ow">not</span> <span class="n">expected_keys_present</span><span class="p">:</span>
                         <span class="k">raise</span> <span class="ne">AssertionError</span><span class="p">(</span><span class="s2">&quot;Expected standard keys in multimodal output dict.&quot;</span><span class="p">)</span>

                    <span class="k">for</span> <span class="n">key_feat</span><span class="p">,</span> <span class="n">val_feat</span> <span class="ow">in</span> <span class="n">features</span><span class="o">.</span><span class="n">items</span><span class="p">():</span> 
                        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">val_feat</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">):</span>
                            <span class="k">raise</span> <span class="ne">AssertionError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Multimodal feature &#39;</span><span class="si">{</span><span class="n">key_feat</span><span class="si">}</span><span class="s2">&#39; not a numpy array.&quot;</span><span class="p">)</span>
                        <span class="n">mm_dim_config</span> <span class="o">=</span> <span class="n">extractor</span><span class="o">.</span><span class="n">get_feature_dimension</span><span class="p">()</span>
                        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">mm_dim_config</span><span class="p">,</span> <span class="nb">dict</span><span class="p">):</span>
                            <span class="n">main_key_part</span> <span class="o">=</span> <span class="n">key_feat</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;_&#39;</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span> 
                            <span class="k">if</span> <span class="n">main_key_part</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">mm_dim_config</span><span class="p">:</span>
                                <span class="k">if</span> <span class="n">model_name</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s2">&quot;xclip&quot;</span><span class="p">)</span> <span class="ow">and</span> <span class="n">main_key_part</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;video&quot;</span><span class="p">,</span> <span class="s2">&quot;text&quot;</span><span class="p">]:</span> <span class="c1"># XCLIP dim is single value</span>
                                    <span class="n">expected_dim_mm</span> <span class="o">=</span> <span class="n">mm_dim_config</span> 
                                <span class="k">else</span><span class="p">:</span>
                                    <span class="k">raise</span> <span class="ne">AssertionError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Dimension key &#39;</span><span class="si">{</span><span class="n">main_key_part</span><span class="si">}</span><span class="s2">&#39; not in model&#39;s dim config </span><span class="si">{</span><span class="n">mm_dim_config</span><span class="si">}</span><span class="s2"> for feature key &#39;</span><span class="si">{</span><span class="n">key_feat</span><span class="si">}</span><span class="s2">&#39;&quot;</span><span class="p">)</span>
                            <span class="k">else</span><span class="p">:</span>
                                <span class="n">expected_dim_mm</span> <span class="o">=</span> <span class="n">mm_dim_config</span><span class="p">[</span><span class="n">main_key_part</span><span class="p">]</span>
                        <span class="k">else</span><span class="p">:</span> 
                            <span class="n">expected_dim_mm</span> <span class="o">=</span> <span class="n">mm_dim_config</span>

                        <span class="k">if</span> <span class="n">val_feat</span><span class="o">.</span><span class="n">shape</span> <span class="o">!=</span> <span class="p">(</span><span class="n">expected_batch_size</span><span class="p">,</span> <span class="n">expected_dim_mm</span><span class="p">):</span>
                             <span class="k">raise</span> <span class="ne">AssertionError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Multimodal feature &#39;</span><span class="si">{</span><span class="n">key_feat</span><span class="si">}</span><span class="s2">&#39; shape mismatch. Got </span><span class="si">{</span><span class="n">val_feat</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">, expected (</span><span class="si">{</span><span class="n">expected_batch_size</span><span class="si">}</span><span class="s2">, </span><span class="si">{</span><span class="n">expected_dim_mm</span><span class="si">}</span><span class="s2">)&quot;</span><span class="p">)</span>
                <span class="k">else</span><span class="p">:</span> 
                    <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">features</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">):</span>
                        <span class="k">raise</span> <span class="ne">AssertionError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Features not a numpy array (got </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">features</span><span class="p">)</span><span class="si">}</span><span class="s2">)&quot;</span><span class="p">)</span>
                    <span class="n">expected_dim_uni</span> <span class="o">=</span> <span class="n">extractor</span><span class="o">.</span><span class="n">get_feature_dimension</span><span class="p">()</span>
                    <span class="c1"># Handle case where expected_dim_uni itself might be a dict for some misconfigured unimodal model (should not happen)</span>
                    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">expected_dim_uni</span><span class="p">,</span> <span class="nb">dict</span><span class="p">):</span> 
                        <span class="k">raise</span> <span class="ne">AssertionError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Unimodal model &#39;</span><span class="si">{</span><span class="n">model_name</span><span class="si">}</span><span class="s2">&#39; has dict for feature_dimension: </span><span class="si">{</span><span class="n">expected_dim_uni</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

                    <span class="k">if</span> <span class="n">features</span><span class="o">.</span><span class="n">shape</span> <span class="o">!=</span> <span class="p">(</span><span class="n">expected_batch_size</span><span class="p">,</span> <span class="n">expected_dim_uni</span><span class="p">):</span>
                        <span class="k">raise</span> <span class="ne">AssertionError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Feature shape mismatch. Got </span><span class="si">{</span><span class="n">features</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">, expected (</span><span class="si">{</span><span class="n">expected_batch_size</span><span class="si">}</span><span class="s2">, </span><span class="si">{</span><span class="n">expected_dim_uni</span><span class="si">}</span><span class="s2">)&quot;</span><span class="p">)</span>
                
                <span class="n">current_result</span><span class="p">[</span><span class="s2">&quot;test_status&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;PASSED&quot;</span>
                <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span> <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;[</span><span class="si">{</span><span class="n">model_name</span><span class="si">}</span><span class="s2">] Feature extraction and validation PASSED.&quot;</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span> 
                <span class="n">current_result</span><span class="p">[</span><span class="s2">&quot;test_status&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;SKIPPED&quot;</span>
                <span class="k">if</span> <span class="ow">not</span> <span class="n">is_video_task_with_placeholder</span><span class="p">:</span> 
                    <span class="n">notes_collector</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s2">&quot;No dummy data prepared.&quot;</span><span class="p">)</span>
                <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span> <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;[</span><span class="si">{</span><span class="n">model_name</span><span class="si">}</span><span class="s2">] SKIPPED (No dummy data prepared).&quot;</span><span class="p">)</span>


        <span class="k">except</span> <span class="ne">ImportError</span> <span class="k">as</span> <span class="n">ie</span><span class="p">:</span>
            <span class="n">current_result</span><span class="p">[</span><span class="s2">&quot;availability&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;✗ (Import)&quot;</span>
            <span class="n">current_result</span><span class="p">[</span><span class="s2">&quot;test_status&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;FAILED&quot;</span>
            <span class="n">short_msg</span> <span class="o">=</span> <span class="n">textwrap</span><span class="o">.</span><span class="n">shorten</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">ie</span><span class="p">)</span><span class="o">.</span><span class="n">splitlines</span><span class="p">()[</span><span class="mi">0</span><span class="p">],</span> <span class="n">width</span><span class="o">=</span><span class="mi">60</span><span class="p">,</span> <span class="n">placeholder</span><span class="o">=</span><span class="s2">&quot;...&quot;</span><span class="p">)</span>
            <span class="n">notes_collector</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">ie</span><span class="p">)</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">short_msg</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span> <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;[</span><span class="si">{</span><span class="n">model_name</span><span class="si">}</span><span class="s2">] FAILED (Initialization ImportError): </span><span class="si">{</span><span class="n">ie</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">current_result</span><span class="p">[</span><span class="s2">&quot;availability&quot;</span><span class="p">]</span> <span class="o">==</span> <span class="s2">&quot;✓&quot;</span><span class="p">:</span> 
                <span class="n">current_result</span><span class="p">[</span><span class="s2">&quot;test_status&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;FAILED (Runtime)&quot;</span>
            <span class="k">else</span><span class="p">:</span> 
                <span class="n">current_result</span><span class="p">[</span><span class="s2">&quot;availability&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;✗ (Init Error)&quot;</span>
                <span class="n">current_result</span><span class="p">[</span><span class="s2">&quot;test_status&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;FAILED&quot;</span>
            <span class="n">short_msg</span> <span class="o">=</span> <span class="n">textwrap</span><span class="o">.</span><span class="n">shorten</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">e</span><span class="p">)</span><span class="o">.</span><span class="n">splitlines</span><span class="p">()[</span><span class="mi">0</span><span class="p">],</span> <span class="n">width</span><span class="o">=</span><span class="mi">60</span><span class="p">,</span> <span class="n">placeholder</span><span class="o">=</span><span class="s2">&quot;...&quot;</span><span class="p">)</span>
            <span class="n">notes_collector</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">e</span><span class="p">)</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">short_msg</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span> <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;[</span><span class="si">{</span><span class="n">model_name</span><span class="si">}</span><span class="s2">] FAILED (</span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">e</span><span class="p">)</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2">): </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        
        <span class="n">current_result</span><span class="p">[</span><span class="s2">&quot;notes&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;; &quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">notes_collector</span><span class="p">)</span> <span class="k">if</span> <span class="n">notes_collector</span> <span class="k">else</span> <span class="s2">&quot;&quot;</span>
        <span class="n">test_results_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">current_result</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">dummy_image_path</span> <span class="ow">and</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">dummy_image_path</span><span class="p">):</span> <span class="n">os</span><span class="o">.</span><span class="n">remove</span><span class="p">(</span><span class="n">dummy_image_path</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">dummy_audio_path</span> <span class="ow">and</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">dummy_audio_path</span><span class="p">):</span> <span class="n">os</span><span class="o">.</span><span class="n">remove</span><span class="p">(</span><span class="n">dummy_audio_path</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">dummy_video_path</span> <span class="ow">and</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">dummy_video_path</span><span class="p">):</span> <span class="n">os</span><span class="o">.</span><span class="n">remove</span><span class="p">(</span><span class="n">dummy_video_path</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span> <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Dummy files cleaned up.&quot;</span><span class="p">)</span>

    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n\n</span><span class="s2">&quot;</span> <span class="o">+</span> <span class="s2">&quot;=&quot;</span><span class="o">*</span><span class="mi">80</span><span class="p">)</span> 
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot; DLFeat Self-Test Summary Report&quot;</span><span class="o">.</span><span class="n">center</span><span class="p">(</span><span class="mi">80</span><span class="p">))</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;=&quot;</span><span class="o">*</span><span class="mi">80</span><span class="p">)</span>
    
    <span class="n">col_model_name</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="mi">25</span><span class="p">,</span> <span class="nb">max</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">r</span><span class="p">[</span><span class="s2">&quot;model_name&quot;</span><span class="p">])</span> <span class="k">for</span> <span class="n">r</span> <span class="ow">in</span> <span class="n">test_results_list</span><span class="p">)</span> <span class="k">if</span> <span class="n">test_results_list</span> <span class="k">else</span> <span class="mi">25</span><span class="p">)</span> <span class="c1"># Increased for longer names</span>
    <span class="n">col_task</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="nb">max</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">r</span><span class="p">[</span><span class="s2">&quot;task&quot;</span><span class="p">])</span> <span class="k">for</span> <span class="n">r</span> <span class="ow">in</span> <span class="n">test_results_list</span><span class="p">)</span> <span class="k">if</span> <span class="n">test_results_list</span> <span class="k">else</span> <span class="mi">12</span><span class="p">)</span>
    <span class="n">col_source</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="nb">max</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">r</span><span class="p">[</span><span class="s2">&quot;source&quot;</span><span class="p">])</span> <span class="k">for</span> <span class="n">r</span> <span class="ow">in</span> <span class="n">test_results_list</span><span class="p">)</span> <span class="k">if</span> <span class="n">test_results_list</span> <span class="k">else</span> <span class="mi">15</span><span class="p">)</span>
    <span class="n">col_avail</span> <span class="o">=</span> <span class="mi">10</span> 
    <span class="n">col_status</span> <span class="o">=</span> <span class="mi">22</span> 
    
    <span class="n">preferred_total_width</span> <span class="o">=</span> <span class="mi">140</span> <span class="c1"># Adjusted preferred width for more notes</span>
    <span class="n">col_notes</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="n">preferred_total_width</span> <span class="o">-</span> <span class="p">(</span><span class="n">col_model_name</span> <span class="o">+</span> <span class="n">col_task</span> <span class="o">+</span> <span class="n">col_source</span> <span class="o">+</span> <span class="n">col_avail</span> <span class="o">+</span> <span class="n">col_status</span> <span class="o">+</span> <span class="p">(</span><span class="mi">6</span><span class="o">*</span><span class="mi">3</span><span class="p">)</span> <span class="o">+</span> <span class="mi">7</span><span class="p">))</span> <span class="c1"># +7 for extra chars in header</span>


    <span class="n">header</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;| </span><span class="si">{</span><span class="s1">&#39;Model&#39;</span><span class="o">.</span><span class="n">ljust</span><span class="p">(</span><span class="n">col_model_name</span><span class="p">)</span><span class="si">}</span><span class="s2"> | </span><span class="si">{</span><span class="s1">&#39;Task&#39;</span><span class="o">.</span><span class="n">ljust</span><span class="p">(</span><span class="n">col_task</span><span class="p">)</span><span class="si">}</span><span class="s2"> | </span><span class="si">{</span><span class="s1">&#39;Source&#39;</span><span class="o">.</span><span class="n">ljust</span><span class="p">(</span><span class="n">col_source</span><span class="p">)</span><span class="si">}</span><span class="s2"> | </span><span class="si">{</span><span class="s1">&#39;Available&#39;</span><span class="o">.</span><span class="n">ljust</span><span class="p">(</span><span class="n">col_avail</span><span class="p">)</span><span class="si">}</span><span class="s2"> | </span><span class="si">{</span><span class="s1">&#39;Test Status&#39;</span><span class="o">.</span><span class="n">ljust</span><span class="p">(</span><span class="n">col_status</span><span class="p">)</span><span class="si">}</span><span class="s2"> | Notes</span><span class="si">{</span><span class="s1">&#39; &#39;</span><span class="o">.</span><span class="n">ljust</span><span class="p">(</span><span class="n">col_notes</span><span class="o">-</span><span class="mi">5</span><span class="p">)</span><span class="si">}</span><span class="s2"> |&quot;</span>
    <span class="n">separator</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;|</span><span class="si">{</span><span class="s1">&#39;-&#39;</span><span class="o">*</span><span class="p">(</span><span class="n">col_model_name</span><span class="o">+</span><span class="mi">2</span><span class="p">)</span><span class="si">}</span><span class="s2">|</span><span class="si">{</span><span class="s1">&#39;-&#39;</span><span class="o">*</span><span class="p">(</span><span class="n">col_task</span><span class="o">+</span><span class="mi">2</span><span class="p">)</span><span class="si">}</span><span class="s2">|</span><span class="si">{</span><span class="s1">&#39;-&#39;</span><span class="o">*</span><span class="p">(</span><span class="n">col_source</span><span class="o">+</span><span class="mi">2</span><span class="p">)</span><span class="si">}</span><span class="s2">|</span><span class="si">{</span><span class="s1">&#39;-&#39;</span><span class="o">*</span><span class="p">(</span><span class="n">col_avail</span><span class="o">+</span><span class="mi">2</span><span class="p">)</span><span class="si">}</span><span class="s2">|</span><span class="si">{</span><span class="s1">&#39;-&#39;</span><span class="o">*</span><span class="p">(</span><span class="n">col_status</span><span class="o">+</span><span class="mi">2</span><span class="p">)</span><span class="si">}</span><span class="s2">|</span><span class="si">{</span><span class="s1">&#39;-&#39;</span><span class="o">*</span><span class="p">(</span><span class="n">col_notes</span><span class="o">+</span><span class="mi">2</span><span class="p">)</span><span class="si">}</span><span class="s2">|&quot;</span>
    
    <span class="nb">print</span><span class="p">(</span><span class="n">separator</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">header</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">separator</span><span class="p">)</span>

    <span class="k">for</span> <span class="n">r</span> <span class="ow">in</span> <span class="n">test_results_list</span><span class="p">:</span>
        <span class="n">avail_str</span> <span class="o">=</span> <span class="n">r</span><span class="p">[</span><span class="s2">&quot;availability&quot;</span><span class="p">]</span>
        <span class="n">status_str</span> <span class="o">=</span> <span class="n">r</span><span class="p">[</span><span class="s2">&quot;test_status&quot;</span><span class="p">]</span>
        
        <span class="k">if</span> <span class="s2">&quot;✓&quot;</span> <span class="ow">in</span> <span class="n">avail_str</span><span class="p">:</span> <span class="n">avail_display</span> <span class="o">=</span> <span class="s2">&quot;✓&quot;</span><span class="o">.</span><span class="n">center</span><span class="p">(</span><span class="n">col_avail</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span> <span class="n">avail_display</span> <span class="o">=</span> <span class="n">avail_str</span><span class="o">.</span><span class="n">ljust</span><span class="p">(</span><span class="n">col_avail</span><span class="p">)</span> 

        <span class="k">if</span> <span class="s2">&quot;PASSED&quot;</span> <span class="ow">in</span> <span class="n">status_str</span><span class="p">:</span> <span class="n">status_display</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;✓ </span><span class="si">{</span><span class="n">status_str</span><span class="si">}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">ljust</span><span class="p">(</span><span class="n">col_status</span><span class="p">)</span>
        <span class="k">elif</span> <span class="s2">&quot;FAILED&quot;</span> <span class="ow">in</span> <span class="n">status_str</span><span class="p">:</span> <span class="n">status_display</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;✗ </span><span class="si">{</span><span class="n">status_str</span><span class="si">}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">ljust</span><span class="p">(</span><span class="n">col_status</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span> <span class="n">status_display</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;~ </span><span class="si">{</span><span class="n">status_str</span><span class="si">}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">ljust</span><span class="p">(</span><span class="n">col_status</span><span class="p">)</span> <span class="c1"># SKIPPED (Transform) or SKIPPED</span>

        <span class="n">model_disp</span> <span class="o">=</span> <span class="n">textwrap</span><span class="o">.</span><span class="n">shorten</span><span class="p">(</span><span class="n">r</span><span class="p">[</span><span class="s2">&quot;model_name&quot;</span><span class="p">],</span> <span class="n">width</span><span class="o">=</span><span class="n">col_model_name</span><span class="p">,</span> <span class="n">placeholder</span><span class="o">=</span><span class="s2">&quot;..&quot;</span><span class="p">)</span>
        <span class="n">task_disp</span> <span class="o">=</span> <span class="n">textwrap</span><span class="o">.</span><span class="n">shorten</span><span class="p">(</span><span class="n">r</span><span class="p">[</span><span class="s2">&quot;task&quot;</span><span class="p">],</span> <span class="n">width</span><span class="o">=</span><span class="n">col_task</span><span class="p">,</span> <span class="n">placeholder</span><span class="o">=</span><span class="s2">&quot;..&quot;</span><span class="p">)</span>
        <span class="n">source_disp</span> <span class="o">=</span> <span class="n">textwrap</span><span class="o">.</span><span class="n">shorten</span><span class="p">(</span><span class="n">r</span><span class="p">[</span><span class="s2">&quot;source&quot;</span><span class="p">],</span> <span class="n">width</span><span class="o">=</span><span class="n">col_source</span><span class="p">,</span> <span class="n">placeholder</span><span class="o">=</span><span class="s2">&quot;..&quot;</span><span class="p">)</span>
        <span class="n">notes_disp</span> <span class="o">=</span> <span class="n">textwrap</span><span class="o">.</span><span class="n">shorten</span><span class="p">(</span><span class="n">r</span><span class="p">[</span><span class="s2">&quot;notes&quot;</span><span class="p">],</span> <span class="n">width</span><span class="o">=</span><span class="n">col_notes</span><span class="p">,</span> <span class="n">placeholder</span><span class="o">=</span><span class="s2">&quot;..&quot;</span><span class="p">)</span>

        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;| </span><span class="si">{</span><span class="n">model_disp</span><span class="o">.</span><span class="n">ljust</span><span class="p">(</span><span class="n">col_model_name</span><span class="p">)</span><span class="si">}</span><span class="s2"> | </span><span class="si">{</span><span class="n">task_disp</span><span class="o">.</span><span class="n">ljust</span><span class="p">(</span><span class="n">col_task</span><span class="p">)</span><span class="si">}</span><span class="s2"> | </span><span class="si">{</span><span class="n">source_disp</span><span class="o">.</span><span class="n">ljust</span><span class="p">(</span><span class="n">col_source</span><span class="p">)</span><span class="si">}</span><span class="s2"> | </span><span class="si">{</span><span class="n">avail_display</span><span class="si">}</span><span class="s2"> | </span><span class="si">{</span><span class="n">status_display</span><span class="si">}</span><span class="s2"> | </span><span class="si">{</span><span class="n">notes_disp</span><span class="o">.</span><span class="n">ljust</span><span class="p">(</span><span class="n">col_notes</span><span class="p">)</span><span class="si">}</span><span class="s2"> |&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">separator</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;=&quot;</span><span class="o">*</span><span class="mi">80</span><span class="p">)</span>
    
    <span class="k">return</span> <span class="n">test_results_list</span></div>



<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s1">&#39;__main__&#39;</span><span class="p">:</span>
    <span class="n">results</span> <span class="o">=</span> <span class="n">run_self_tests</span><span class="p">()</span> 
</pre></div>

           </div>
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2025, Your Name/Gemini.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>