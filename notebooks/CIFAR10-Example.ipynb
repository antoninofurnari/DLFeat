{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# DLFeat - CIFAR-10 Classification Example\n",
        "\n",
        "This notebook demonstrates:\n",
        "1. Loading the CIFAR-10 image dataset using torchvision.datasets.\n",
        "2. Extracting features using DLFeat.\n",
        "3. Training a K-Nearest Neighbors (KNN) classifier on these features.\n",
        "4. Evaluating the classifier.\n",
        "\n",
        "Let's start by installing the library:"
      ],
      "metadata": {
        "id": "6Kyfr2TAuE3p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install git+https://github.com/antoninofurnari/dlfeat.git"
      ],
      "metadata": {
        "id": "kJMDMz2tuKBZ",
        "outputId": "1d5b5127-24b8-4cad-ce0f-3983ab45733e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/antoninofurnari/dlfeat.git\n",
            "  Cloning https://github.com/antoninofurnari/dlfeat.git to /tmp/pip-req-build-9zol4ecd\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/antoninofurnari/dlfeat.git /tmp/pip-req-build-9zol4ecd\n",
            "  Resolved https://github.com/antoninofurnari/dlfeat.git to commit a13c2787251780f7031f180e7b38a5b39f4ec25e\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from dlfeat==0.6.0) (2.6.0+cu124)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.11/dist-packages (from dlfeat==0.6.0) (2.0.2)\n",
            "Requirement already satisfied: scikit-learn>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from dlfeat==0.6.0) (1.6.1)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.24.0->dlfeat==0.6.0) (1.15.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.24.0->dlfeat==0.6.0) (1.5.0)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.24.0->dlfeat==0.6.0) (3.6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.0->dlfeat==0.6.0) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.0->dlfeat==0.6.0) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.0->dlfeat==0.6.0) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.0->dlfeat==0.6.0) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.0->dlfeat==0.6.0) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.9.0->dlfeat==0.6.0)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.9.0->dlfeat==0.6.0)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.9.0->dlfeat==0.6.0)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.9.0->dlfeat==0.6.0)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.9.0->dlfeat==0.6.0)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.9.0->dlfeat==0.6.0)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.9.0->dlfeat==0.6.0)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.9.0->dlfeat==0.6.0)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.9.0->dlfeat==0.6.0)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.0->dlfeat==0.6.0) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.0->dlfeat==0.6.0) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.0->dlfeat==0.6.0) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.9.0->dlfeat==0.6.0)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.0->dlfeat==0.6.0) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.0->dlfeat==0.6.0) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.9.0->dlfeat==0.6.0) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.9.0->dlfeat==0.6.0) (3.0.2)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m113.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m87.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m44.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m92.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: dlfeat\n",
            "  Building wheel for dlfeat (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for dlfeat: filename=dlfeat-0.6.0-py3-none-any.whl size=18016 sha256=2a8558fba102ea2cc0061302a2cfd211b067beaf265e4e33db12256965827544\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-vrpt6mxq/wheels/73/0a/3c/ab77217782e85cc78dd0ea399f3e96ea6c809e4221d209a5fb\n",
            "Successfully built dlfeat\n",
            "Installing collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, dlfeat\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed dlfeat-0.6.0 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "You'll also need scikit-learn, Pillow, numpy, torch, torchvision for this example. These are generally installed in Colab, but you can install them with the following command if needed:\n",
        "\n",
        "```\n",
        "pip install scikit-learn Pillow numpy torch torchvision\n",
        "```\n",
        "\n",
        "The code is reported below:"
      ],
      "metadata": {
        "id": "CZ8Aw0nUuRff"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mMX2ULum4r8q",
        "outputId": "8d70fe96-8c7b-402d-ad68-d7dba6c02955"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- DLFeat CIFAR-10 & KNN Classification Demo ---\n",
            "\n",
            "1. Loading CIFAR-10 dataset...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170M/170M [00:06<00:00, 27.7MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Subset of dataset loaded: 5000 training samples, 1000 testing samples.\n",
            "   Sample image type: <class 'PIL.Image.Image'>, mode: RGB, size: (32, 32)\n",
            "   Number of classes: 10\n",
            "\n",
            "2. Initializing DLFeatExtractor with model: resnet18...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
            "100%|██████████| 44.7M/44.7M [00:00<00:00, 120MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   DLFeatExtractor for 'resnet18' initialized successfully.\n",
            "   Feature dimension will be: 512\n",
            "\n",
            "3. Extracting features for training set (this might take a moment)...\n",
            "   Training features shape: (5000, 512)\n",
            "   Extracting features for testing set...\n",
            "   Testing features shape: (1000, 512)\n",
            "\n",
            "4. Training KNN classifier on DLFeat features...\n",
            "   KNN classifier (DLFeat) trained.\n",
            "\n",
            "5. Making predictions and evaluating (DLFeat Features)...\n",
            "   Accuracy of KNN on DLFeat ('resnet18') features: 72.30%\n",
            "\n",
            "6. Training KNN classifier on raw pixel data (for comparison)...\n",
            "   KNN classifier (Raw Pixels) trained.\n",
            "   Making predictions and evaluating (Raw Pixels)...\n",
            "   Accuracy of KNN on raw pixel data: 26.60%\n",
            "\n",
            "--- Demo Finished ---\n",
            "Note: Features from models like ResNet18 (pre-trained on ImageNet) are general-purpose.\n",
            "While they can improve performance over raw pixels for many tasks,\n",
            "fine-tuning the feature extractor or using domain-specific models might yield even better results.\n"
          ]
        }
      ],
      "source": [
        "from dlfeat import DLFeatExtractor\n",
        "from torchvision.datasets import CIFAR10\n",
        "from torchvision import transforms as tv_transforms # Use a different alias for torchvision transforms\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import os\n",
        "\n",
        "print(\"--- DLFeat CIFAR-10 & KNN Classification Demo ---\")\n",
        "\n",
        "# --- 1. Load CIFAR-10 Dataset ---\n",
        "print(\"\\n1. Loading CIFAR-10 dataset...\")\n",
        "# CIFAR-10 images are 32x32. torchvision.datasets returns PIL Images by default.\n",
        "# We'll download it if not present.\n",
        "try:\n",
        "    # Using a transform to get PIL Images directly if not default\n",
        "    # By default, CIFAR10 returns PIL Image if transform is None or doesn't include ToTensor\n",
        "    cifar10_train_raw = CIFAR10(root='./cifar_data', train=True, download=True)\n",
        "    cifar10_test_raw = CIFAR10(root='./cifar_data', train=False, download=True)\n",
        "\n",
        "    # Extract a subset for faster demonstration (e.g., first 5000 train, 1000 test)\n",
        "    # Full dataset: 50000 train, 10000 test\n",
        "    num_train_samples = 5000\n",
        "    num_test_samples = 1000\n",
        "\n",
        "    X_train_pil = [cifar10_train_raw[i][0] for i in range(num_train_samples)] # PIL Images\n",
        "    y_train = [cifar10_train_raw[i][1] for i in range(num_train_samples)]\n",
        "\n",
        "    X_test_pil = [cifar10_test_raw[i][0] for i in range(num_test_samples)] # PIL Images\n",
        "    y_test = [cifar10_test_raw[i][1] for i in range(num_test_samples)]\n",
        "\n",
        "    # Also get raw pixel data for comparison (flattened)\n",
        "    # To do this, we need to convert PIL to numpy and flatten\n",
        "    X_train_raw_pixels_flat = np.array([np.array(img).flatten() for img in X_train_pil])\n",
        "    X_test_raw_pixels_flat = np.array([np.array(img).flatten() for img in X_test_pil])\n",
        "\n",
        "\n",
        "    print(f\"   Subset of dataset loaded: {len(X_train_pil)} training samples, {len(X_test_pil)} testing samples.\")\n",
        "    print(f\"   Sample image type: {type(X_train_pil[0])}, mode: {X_train_pil[0].mode}, size: {X_train_pil[0].size}\")\n",
        "    print(f\"   Number of classes: {len(cifar10_train_raw.classes)}\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Error loading or processing CIFAR-10: {e}\")\n",
        "    print(\"Please ensure you have an internet connection for download and torchvision is working.\")\n",
        "    print(\"Exiting demo.\")\n",
        "    exit()\n",
        "\n",
        "\n",
        "# --- 2. Initialize DLFeatExtractor ---\n",
        "# Using resnet18, which is relatively fast.\n",
        "MODEL_NAME = \"resnet18\"\n",
        "print(f\"\\n2. Initializing DLFeatExtractor with model: {MODEL_NAME}...\")\n",
        "try:\n",
        "    feature_extractor = DLFeatExtractor(model_name=MODEL_NAME, task_type=\"image\")\n",
        "    print(f\"   DLFeatExtractor for '{MODEL_NAME}' initialized successfully.\")\n",
        "    print(f\"   Feature dimension will be: {feature_extractor.get_feature_dimension()}\")\n",
        "except Exception as e:\n",
        "    print(f\"   Error initializing DLFeatExtractor: {e}\")\n",
        "    print(\"   Ensure the model is configured in DLFeat and dependencies are met.\")\n",
        "    print(\"   Exiting demo.\")\n",
        "    exit()\n",
        "\n",
        "# --- 3. Extract Features ---\n",
        "# The 'fit' method is for scikit-learn compatibility and typically does nothing here.\n",
        "print(\"\\n3. Extracting features for training set (this might take a moment)...\")\n",
        "# DLFeatExtractor expects a list of PIL Images or file paths. X_train_pil is already a list of PIL Images.\n",
        "feature_extractor.fit(X_train_pil)\n",
        "X_train_features = feature_extractor.transform(X_train_pil)\n",
        "print(f\"   Training features shape: {X_train_features.shape}\")\n",
        "\n",
        "print(\"   Extracting features for testing set...\")\n",
        "X_test_features = feature_extractor.transform(X_test_pil)\n",
        "print(f\"   Testing features shape: {X_test_features.shape}\")\n",
        "\n",
        "# --- 4. Train KNN Classifier on DLFeat Features ---\n",
        "print(\"\\n4. Training KNN classifier on DLFeat features...\")\n",
        "knn_classifier_dlfeat = KNeighborsClassifier(n_neighbors=5)\n",
        "knn_classifier_dlfeat.fit(X_train_features, y_train)\n",
        "print(\"   KNN classifier (DLFeat) trained.\")\n",
        "\n",
        "# --- 5. Make Predictions and Evaluate (DLFeat Features) ---\n",
        "print(\"\\n5. Making predictions and evaluating (DLFeat Features)...\")\n",
        "y_pred_dlfeat = knn_classifier_dlfeat.predict(X_test_features)\n",
        "accuracy_dlfeat = accuracy_score(y_test, y_pred_dlfeat)\n",
        "print(f\"   Accuracy of KNN on DLFeat ('{MODEL_NAME}') features: {accuracy_dlfeat*100:.2f}%\")\n",
        "\n",
        "# --- 6. For comparison: KNN on Raw Pixel Data ---\n",
        "print(\"\\n6. Training KNN classifier on raw pixel data (for comparison)...\")\n",
        "knn_classifier_raw = KNeighborsClassifier(n_neighbors=5)\n",
        "knn_classifier_raw.fit(X_train_raw_pixels_flat, y_train)\n",
        "print(\"   KNN classifier (Raw Pixels) trained.\")\n",
        "\n",
        "print(\"   Making predictions and evaluating (Raw Pixels)...\")\n",
        "y_pred_raw = knn_classifier_raw.predict(X_test_raw_pixels_flat)\n",
        "accuracy_raw = accuracy_score(y_test, y_pred_raw)\n",
        "print(f\"   Accuracy of KNN on raw pixel data: {accuracy_raw*100:.2f}%\")\n",
        "\n",
        "\n",
        "print(\"\\n--- Demo Finished ---\")\n",
        "print(\"Note: Features from models like ResNet18 (pre-trained on ImageNet) are general-purpose.\")\n",
        "print(\"While they can improve performance over raw pixels for many tasks,\")\n",
        "print(\"fine-tuning the feature extractor or using domain-specific models might yield even better results.\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}